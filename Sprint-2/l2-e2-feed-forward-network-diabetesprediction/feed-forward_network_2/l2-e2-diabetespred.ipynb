{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e0ce4ff",
   "metadata": {},
   "source": [
    "# S2 - L2 - E2 - Diabetes prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfaeb71c",
   "metadata": {},
   "source": [
    "This excersise consist in designing and building a feed-forward neural network to predict diabetes diseasse using 'Pima indians diabetes database'. 'Outcome' will be the target column. 0 means no diseasse , 1 diabetes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d73513",
   "metadata": {},
   "source": [
    "## 1. Set up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7099d18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from  sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f126b2c8",
   "metadata": {},
   "source": [
    "## 2 Load and explore dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0cdffab1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('diabetes.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca51a49",
   "metadata": {},
   "source": [
    "Search for NaNs and inconsistencies in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "101f184e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Información del dataset:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 768 entries, 0 to 767\n",
      "Data columns (total 9 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Pregnancies               768 non-null    int64  \n",
      " 1   Glucose                   768 non-null    int64  \n",
      " 2   BloodPressure             768 non-null    int64  \n",
      " 3   SkinThickness             768 non-null    int64  \n",
      " 4   Insulin                   768 non-null    int64  \n",
      " 5   BMI                       768 non-null    float64\n",
      " 6   DiabetesPedigreeFunction  768 non-null    float64\n",
      " 7   Age                       768 non-null    int64  \n",
      " 8   Outcome                   768 non-null    int64  \n",
      "dtypes: float64(2), int64(7)\n",
      "memory usage: 54.1 KB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\nInformación del dataset:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f48535",
   "metadata": {},
   "source": [
    "Cleaning and data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "baa9acdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores nulos por columna: \n",
      "\n",
      "Pregnancies                 0\n",
      "Glucose                     0\n",
      "BloodPressure               0\n",
      "SkinThickness               0\n",
      "Insulin                     0\n",
      "BMI                         0\n",
      "DiabetesPedigreeFunction    0\n",
      "Age                         0\n",
      "Outcome                     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Valores nulos por columna: \\n')\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b938cb33",
   "metadata": {},
   "source": [
    "\n",
    "Replace non sense zeros with column average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f997f813",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_with_zeros = [\"Glucose\", \"BloodPressure\", \"SkinThickness\", \"Insulin\", \"BMI\"]\n",
    "for col in cols_with_zeros:\n",
    "    df[col] = df[col].replace(0,df[col].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3368768f",
   "metadata": {},
   "source": [
    "## 3. Set up dataset for classifcation Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d487f3",
   "metadata": {},
   "source": [
    "Separe features and target columns, transform to values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "054d0b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns='Outcome').values\n",
    "y = df['Outcome'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe7935e",
   "metadata": {},
   "source": [
    "Split in train and test sets, then scale them and transform to tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f6acfe82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split dataset\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.25,random_state=42, stratify=y)\n",
    "\n",
    "#scale vars to speed up  convergence\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)\n",
    "\n",
    "#transform to tensors\n",
    "\n",
    "X_train_t = torch.tensor(X_train, dtype = torch.float32)\n",
    "X_test_t = torch.tensor(X_test, dtype = torch.float32)\n",
    "y_train_t = torch.tensor(y_train, dtype = torch.float32)\n",
    "y_test_t = torch.tensor(y_test, dtype = torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7217fc2e",
   "metadata": {},
   "source": [
    "## 4. Build feed-forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cb2f7ab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DiabetesNN(\n",
      "  (fc1): Linear(in_features=8, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=32, bias=True)\n",
      "  (out): Linear(in_features=32, out_features=1, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class DiabetesNN(nn.Module):\n",
    "    def __init__(self):\n",
    "\n",
    "        super(DiabetesNN,self).__init__()\n",
    "        self.fc1 = nn.Linear(8,64)\n",
    "        self.fc2 = nn.Linear(64,32)\n",
    "        self.out = nn.Linear(32,1)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self,x):\n",
    "        \n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.sigmoid(self.out(x))\n",
    "        return x\n",
    "    \n",
    "model = DiabetesNN()\n",
    "print(model)\n",
    "\n",
    "\n",
    "                \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105d7ce5",
   "metadata": {},
   "source": [
    "Defining Loss function (binary cross entropy) and optimizer (Adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0d855427",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d81bf05",
   "metadata": {},
   "source": [
    "## 5. Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5b46f0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_t = y_train_t.view(-1, 1)\n",
    "y_test_t = y_test_t.view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "762ff1f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/200] - Loss: 0.669334\n",
      "Epoch [2/200] - Loss: 0.662339\n",
      "Epoch [3/200] - Loss: 0.655481\n",
      "Epoch [4/200] - Loss: 0.648715\n",
      "Epoch [5/200] - Loss: 0.642039\n",
      "Epoch [6/200] - Loss: 0.635448\n",
      "Epoch [7/200] - Loss: 0.628936\n",
      "Epoch [8/200] - Loss: 0.622505\n",
      "Epoch [9/200] - Loss: 0.616159\n",
      "Epoch [10/200] - Loss: 0.609896\n",
      "Epoch [11/200] - Loss: 0.603686\n",
      "Epoch [12/200] - Loss: 0.597531\n",
      "Epoch [13/200] - Loss: 0.591457\n",
      "Epoch [14/200] - Loss: 0.585466\n",
      "Epoch [15/200] - Loss: 0.579561\n",
      "Epoch [16/200] - Loss: 0.573727\n",
      "Epoch [17/200] - Loss: 0.567981\n",
      "Epoch [18/200] - Loss: 0.562330\n",
      "Epoch [19/200] - Loss: 0.556798\n",
      "Epoch [20/200] - Loss: 0.551374\n",
      "Epoch [21/200] - Loss: 0.546077\n",
      "Epoch [22/200] - Loss: 0.540889\n",
      "Epoch [23/200] - Loss: 0.535832\n",
      "Epoch [24/200] - Loss: 0.530921\n",
      "Epoch [25/200] - Loss: 0.526171\n",
      "Epoch [26/200] - Loss: 0.521580\n",
      "Epoch [27/200] - Loss: 0.517139\n",
      "Epoch [28/200] - Loss: 0.512861\n",
      "Epoch [29/200] - Loss: 0.508745\n",
      "Epoch [30/200] - Loss: 0.504786\n",
      "Epoch [31/200] - Loss: 0.500992\n",
      "Epoch [32/200] - Loss: 0.497373\n",
      "Epoch [33/200] - Loss: 0.493906\n",
      "Epoch [34/200] - Loss: 0.490593\n",
      "Epoch [35/200] - Loss: 0.487437\n",
      "Epoch [36/200] - Loss: 0.484439\n",
      "Epoch [37/200] - Loss: 0.481597\n",
      "Epoch [38/200] - Loss: 0.478895\n",
      "Epoch [39/200] - Loss: 0.476336\n",
      "Epoch [40/200] - Loss: 0.473900\n",
      "Epoch [41/200] - Loss: 0.471572\n",
      "Epoch [42/200] - Loss: 0.469346\n",
      "Epoch [43/200] - Loss: 0.467215\n",
      "Epoch [44/200] - Loss: 0.465166\n",
      "Epoch [45/200] - Loss: 0.463196\n",
      "Epoch [46/200] - Loss: 0.461304\n",
      "Epoch [47/200] - Loss: 0.459482\n",
      "Epoch [48/200] - Loss: 0.457720\n",
      "Epoch [49/200] - Loss: 0.456013\n",
      "Epoch [50/200] - Loss: 0.454357\n",
      "Epoch [51/200] - Loss: 0.452745\n",
      "Epoch [52/200] - Loss: 0.451174\n",
      "Epoch [53/200] - Loss: 0.449629\n",
      "Epoch [54/200] - Loss: 0.448123\n",
      "Epoch [55/200] - Loss: 0.446657\n",
      "Epoch [56/200] - Loss: 0.445230\n",
      "Epoch [57/200] - Loss: 0.443847\n",
      "Epoch [58/200] - Loss: 0.442493\n",
      "Epoch [59/200] - Loss: 0.441182\n",
      "Epoch [60/200] - Loss: 0.439908\n",
      "Epoch [61/200] - Loss: 0.438666\n",
      "Epoch [62/200] - Loss: 0.437448\n",
      "Epoch [63/200] - Loss: 0.436259\n",
      "Epoch [64/200] - Loss: 0.435106\n",
      "Epoch [65/200] - Loss: 0.433994\n",
      "Epoch [66/200] - Loss: 0.432919\n",
      "Epoch [67/200] - Loss: 0.431881\n",
      "Epoch [68/200] - Loss: 0.430881\n",
      "Epoch [69/200] - Loss: 0.429918\n",
      "Epoch [70/200] - Loss: 0.428993\n",
      "Epoch [71/200] - Loss: 0.428099\n",
      "Epoch [72/200] - Loss: 0.427232\n",
      "Epoch [73/200] - Loss: 0.426389\n",
      "Epoch [74/200] - Loss: 0.425571\n",
      "Epoch [75/200] - Loss: 0.424774\n",
      "Epoch [76/200] - Loss: 0.423995\n",
      "Epoch [77/200] - Loss: 0.423234\n",
      "Epoch [78/200] - Loss: 0.422486\n",
      "Epoch [79/200] - Loss: 0.421750\n",
      "Epoch [80/200] - Loss: 0.421023\n",
      "Epoch [81/200] - Loss: 0.420306\n",
      "Epoch [82/200] - Loss: 0.419599\n",
      "Epoch [83/200] - Loss: 0.418902\n",
      "Epoch [84/200] - Loss: 0.418209\n",
      "Epoch [85/200] - Loss: 0.417522\n",
      "Epoch [86/200] - Loss: 0.416840\n",
      "Epoch [87/200] - Loss: 0.416159\n",
      "Epoch [88/200] - Loss: 0.415486\n",
      "Epoch [89/200] - Loss: 0.414825\n",
      "Epoch [90/200] - Loss: 0.414170\n",
      "Epoch [91/200] - Loss: 0.413517\n",
      "Epoch [92/200] - Loss: 0.412865\n",
      "Epoch [93/200] - Loss: 0.412218\n",
      "Epoch [94/200] - Loss: 0.411575\n",
      "Epoch [95/200] - Loss: 0.410933\n",
      "Epoch [96/200] - Loss: 0.410296\n",
      "Epoch [97/200] - Loss: 0.409667\n",
      "Epoch [98/200] - Loss: 0.409047\n",
      "Epoch [99/200] - Loss: 0.408436\n",
      "Epoch [100/200] - Loss: 0.407836\n",
      "Epoch [101/200] - Loss: 0.407243\n",
      "Epoch [102/200] - Loss: 0.406650\n",
      "Epoch [103/200] - Loss: 0.406060\n",
      "Epoch [104/200] - Loss: 0.405473\n",
      "Epoch [105/200] - Loss: 0.404887\n",
      "Epoch [106/200] - Loss: 0.404301\n",
      "Epoch [107/200] - Loss: 0.403716\n",
      "Epoch [108/200] - Loss: 0.403132\n",
      "Epoch [109/200] - Loss: 0.402549\n",
      "Epoch [110/200] - Loss: 0.401966\n",
      "Epoch [111/200] - Loss: 0.401375\n",
      "Epoch [112/200] - Loss: 0.400779\n",
      "Epoch [113/200] - Loss: 0.400182\n",
      "Epoch [114/200] - Loss: 0.399592\n",
      "Epoch [115/200] - Loss: 0.399004\n",
      "Epoch [116/200] - Loss: 0.398419\n",
      "Epoch [117/200] - Loss: 0.397834\n",
      "Epoch [118/200] - Loss: 0.397245\n",
      "Epoch [119/200] - Loss: 0.396654\n",
      "Epoch [120/200] - Loss: 0.396059\n",
      "Epoch [121/200] - Loss: 0.395467\n",
      "Epoch [122/200] - Loss: 0.394870\n",
      "Epoch [123/200] - Loss: 0.394272\n",
      "Epoch [124/200] - Loss: 0.393677\n",
      "Epoch [125/200] - Loss: 0.393081\n",
      "Epoch [126/200] - Loss: 0.392480\n",
      "Epoch [127/200] - Loss: 0.391879\n",
      "Epoch [128/200] - Loss: 0.391276\n",
      "Epoch [129/200] - Loss: 0.390676\n",
      "Epoch [130/200] - Loss: 0.390074\n",
      "Epoch [131/200] - Loss: 0.389476\n",
      "Epoch [132/200] - Loss: 0.388874\n",
      "Epoch [133/200] - Loss: 0.388270\n",
      "Epoch [134/200] - Loss: 0.387662\n",
      "Epoch [135/200] - Loss: 0.387051\n",
      "Epoch [136/200] - Loss: 0.386440\n",
      "Epoch [137/200] - Loss: 0.385833\n",
      "Epoch [138/200] - Loss: 0.385227\n",
      "Epoch [139/200] - Loss: 0.384619\n",
      "Epoch [140/200] - Loss: 0.384015\n",
      "Epoch [141/200] - Loss: 0.383413\n",
      "Epoch [142/200] - Loss: 0.382806\n",
      "Epoch [143/200] - Loss: 0.382196\n",
      "Epoch [144/200] - Loss: 0.381583\n",
      "Epoch [145/200] - Loss: 0.380973\n",
      "Epoch [146/200] - Loss: 0.380370\n",
      "Epoch [147/200] - Loss: 0.379769\n",
      "Epoch [148/200] - Loss: 0.379164\n",
      "Epoch [149/200] - Loss: 0.378556\n",
      "Epoch [150/200] - Loss: 0.377953\n",
      "Epoch [151/200] - Loss: 0.377349\n",
      "Epoch [152/200] - Loss: 0.376743\n",
      "Epoch [153/200] - Loss: 0.376137\n",
      "Epoch [154/200] - Loss: 0.375522\n",
      "Epoch [155/200] - Loss: 0.374903\n",
      "Epoch [156/200] - Loss: 0.374288\n",
      "Epoch [157/200] - Loss: 0.373669\n",
      "Epoch [158/200] - Loss: 0.373054\n",
      "Epoch [159/200] - Loss: 0.372431\n",
      "Epoch [160/200] - Loss: 0.371809\n",
      "Epoch [161/200] - Loss: 0.371187\n",
      "Epoch [162/200] - Loss: 0.370571\n",
      "Epoch [163/200] - Loss: 0.369955\n",
      "Epoch [164/200] - Loss: 0.369338\n",
      "Epoch [165/200] - Loss: 0.368727\n",
      "Epoch [166/200] - Loss: 0.368115\n",
      "Epoch [167/200] - Loss: 0.367503\n",
      "Epoch [168/200] - Loss: 0.366893\n",
      "Epoch [169/200] - Loss: 0.366276\n",
      "Epoch [170/200] - Loss: 0.365654\n",
      "Epoch [171/200] - Loss: 0.365036\n",
      "Epoch [172/200] - Loss: 0.364422\n",
      "Epoch [173/200] - Loss: 0.363809\n",
      "Epoch [174/200] - Loss: 0.363199\n",
      "Epoch [175/200] - Loss: 0.362586\n",
      "Epoch [176/200] - Loss: 0.361970\n",
      "Epoch [177/200] - Loss: 0.361359\n",
      "Epoch [178/200] - Loss: 0.360754\n",
      "Epoch [179/200] - Loss: 0.360155\n",
      "Epoch [180/200] - Loss: 0.359559\n",
      "Epoch [181/200] - Loss: 0.358966\n",
      "Epoch [182/200] - Loss: 0.358373\n",
      "Epoch [183/200] - Loss: 0.357784\n",
      "Epoch [184/200] - Loss: 0.357190\n",
      "Epoch [185/200] - Loss: 0.356595\n",
      "Epoch [186/200] - Loss: 0.355999\n",
      "Epoch [187/200] - Loss: 0.355398\n",
      "Epoch [188/200] - Loss: 0.354799\n",
      "Epoch [189/200] - Loss: 0.354207\n",
      "Epoch [190/200] - Loss: 0.353616\n",
      "Epoch [191/200] - Loss: 0.353024\n",
      "Epoch [192/200] - Loss: 0.352428\n",
      "Epoch [193/200] - Loss: 0.351833\n",
      "Epoch [194/200] - Loss: 0.351245\n",
      "Epoch [195/200] - Loss: 0.350658\n",
      "Epoch [196/200] - Loss: 0.350069\n",
      "Epoch [197/200] - Loss: 0.349478\n",
      "Epoch [198/200] - Loss: 0.348889\n",
      "Epoch [199/200] - Loss: 0.348302\n",
      "Epoch [200/200] - Loss: 0.347711\n"
     ]
    }
   ],
   "source": [
    "epochs = 200\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    y_pred = model(X_train_t)\n",
    "\n",
    "    loss = criterion(y_pred, y_train_t)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    if(epochs % 10 ) == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}] - Loss: {loss.item():4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3309f304",
   "metadata": {},
   "source": [
    "## 6. Model performance evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9ff2a0a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Resultados del modelo:\n",
      "Accuracy: 0.7188\n",
      "F1 Score: 0.5846\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.7752    0.8000    0.7874       125\n",
      "         1.0     0.6032    0.5672    0.5846        67\n",
      "\n",
      "    accuracy                         0.7188       192\n",
      "   macro avg     0.6892    0.6836    0.6860       192\n",
      "weighted avg     0.7152    0.7188    0.7166       192\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    y_pred_test = model(X_test_t)\n",
    "    y_pred_labels = (y_pred_test >= 0.5).float()\n",
    "\n",
    "accuracy = accuracy_score(y_test_t,y_pred_labels)\n",
    "f1 = f1_score(y_test_t,y_pred_labels)\n",
    "report = classification_report(y_test_t, y_pred_labels, digits=4)\n",
    "\n",
    "print(\"\\n Resultados del modelo:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(\"\\nClassification Report:\\n\", report)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepLearningEnv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d651bfd4",
   "metadata": {},
   "source": [
    "# Intel Image Classification — PyTorch CNN with Augmentations\n",
    "\n",
    "Este cuaderno implementa **todas** las partes del ejercicio:\n",
    "- Carga de imágenes con `ImageFolder`.\n",
    "- Visualización de muestras originales y transformadas.\n",
    "- **≥5** técnicas de *data augmentation* con `torchvision.transforms`.\n",
    "- CNN con ≥2 capas convolucionales, pooling y capa totalmente conectada.\n",
    "- Entrenamiento (30 épocas) con imágenes **aumentadas**.\n",
    "- Evaluación en imágenes **sin aumento** (precisión y pérdida).\n",
    "\n",
    "**Nota:** Antes de ejecutar, descarga y descomprime el dataset *Intel Image Classification* de Kaggle.\n",
    "Normalmente la estructura es `.../seg_train/` y `.../seg_test/` con 6 clases.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb41ddb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== Imports y configuración ====\n",
    "\n",
    "import os\n",
    "\n",
    "import time\n",
    "\n",
    "import math\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "import torchvision\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "# Comprobación de versión de torchvision (evita conflictos de v2)\n",
    "\n",
    "try:\n",
    "\n",
    "    # En torchvision>=0.15 existe transforms.v2; aquí usamos el API clásico para compatibilidad\n",
    "\n",
    "    _ = transforms.Compose\n",
    "\n",
    "except Exception as e:\n",
    "\n",
    "    raise RuntimeError(\"Se requiere torchvision con 'transforms'.\")\n",
    "\n",
    "\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "DEVICE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad025226",
   "metadata": {},
   "source": [
    "## 1) Rutas del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd92bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajusta esta ruta a la carpeta donde descomprimiste el dataset\n",
    "\n",
    "# Ejemplos de estructuras válidas:\n",
    "\n",
    "# - DATA_DIR/seg_train, DATA_DIR/seg_test\n",
    "\n",
    "# - DATA_DIR/train, DATA_DIR/test\n",
    "\n",
    "DATA_DIR = Path('/path/a/tu/Intel')  # <-- CAMBIA ESTA RUTA\n",
    "\n",
    "\n",
    "\n",
    "def find_split_dirs(root: Path):\n",
    "\n",
    "    \"\"\"Devuelve (train_dir, test_dir) intentando varias convenciones de nombres.\"\"\"\n",
    "\n",
    "    candidates = [\n",
    "\n",
    "        (root/'seg_train', root/'seg_test'),\n",
    "\n",
    "        (root/'train', root/'test'),\n",
    "\n",
    "        (root/'segmentation_data'/'seg_train', root/'segmentation_data'/'seg_test'),\n",
    "\n",
    "    ]\n",
    "\n",
    "    for tr, te in candidates:\n",
    "\n",
    "        if tr.exists() and te.exists():\n",
    "\n",
    "            return tr, te\n",
    "\n",
    "    raise FileNotFoundError(\n",
    "\n",
    "        f\"No se encontraron carpetas de train/test en {root}. Asegúrate de que existan, p.ej. seg_train y seg_test.\")\n",
    "\n",
    "\n",
    "\n",
    "train_dir, test_dir = find_split_dirs(DATA_DIR)\n",
    "\n",
    "print('Train dir:', train_dir)\n",
    "\n",
    "print('Test dir :', test_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c326099",
   "metadata": {},
   "source": [
    "## 2) Transformaciones\n",
    "Se definen dos *pipelines*:\n",
    "- **`tfm_plain`** (sin aumento): *Resize(150×150) → ToTensor → Normalize*.\n",
    "- **`tfm_aug`** (con ≥5 aumentos):\n",
    "  1. `RandomResizedCrop(150)`\n",
    "  2. `RandomHorizontalFlip(0.5)`\n",
    "  3. `RandomRotation(15°)`\n",
    "  4. `ColorJitter` (brillo/contraste/saturación/tono)\n",
    "  5. `RandomGrayscale(p=0.1)`\n",
    "  6. (opcional) `GaussianBlur` si está disponible en tu versión de torchvision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdf2d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 150\n",
    "\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "\n",
    "std  = [0.229, 0.224, 0.225]\n",
    "\n",
    "\n",
    "\n",
    "# Sin aumento (para validación/test y visualización de 'originales')\n",
    "\n",
    "tfm_plain = transforms.Compose([\n",
    "\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "\n",
    "    transforms.ToTensor(),\n",
    "\n",
    "    transforms.Normalize(mean, std)\n",
    "\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "# Con aumento (para entrenamiento)\n",
    "\n",
    "aug_list = [\n",
    "\n",
    "    transforms.RandomResizedCrop(IMG_SIZE, scale=(0.8, 1.0), ratio=(0.9, 1.1)),\n",
    "\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "\n",
    "    transforms.RandomRotation(degrees=15),\n",
    "\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.05),\n",
    "\n",
    "    transforms.RandomGrayscale(p=0.1)\n",
    "\n",
    "]\n",
    "\n",
    "# GaussianBlur es opcional según versión\n",
    "\n",
    "try:\n",
    "\n",
    "    aug_list.append(transforms.GaussianBlur(kernel_size=3))\n",
    "\n",
    "except Exception:\n",
    "\n",
    "    pass\n",
    "\n",
    "\n",
    "\n",
    "tfm_aug = transforms.Compose(aug_list + [\n",
    "\n",
    "    transforms.ToTensor(),\n",
    "\n",
    "    transforms.Normalize(mean, std)\n",
    "\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "# Datasets\n",
    "\n",
    "train_ds_aug   = ImageFolder(train_dir, transform=tfm_aug)\n",
    "\n",
    "train_ds_plain = ImageFolder(train_dir, transform=tfm_plain)\n",
    "\n",
    "test_ds        = ImageFolder(test_dir,  transform=tfm_plain)\n",
    "\n",
    "\n",
    "\n",
    "class_names = train_ds_aug.classes\n",
    "\n",
    "num_classes = len(class_names)\n",
    "\n",
    "class_names, num_classes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ef3dd3",
   "metadata": {},
   "source": [
    "## 3) DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff472b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4  # requerido por el enunciado para la visualización\n",
    "\n",
    "NUM_WORKERS = 2  # ajusta según tu entorno (en Windows puede ser 0)\n",
    "\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_ds_aug, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\n",
    "\n",
    "test_loader  = DataLoader(test_ds,     batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "\n",
    "len(train_loader), len(test_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4465220",
   "metadata": {},
   "source": [
    "## 4) Visualización: originales vs aumentadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2acbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para comparar 'original' vs 'aumentada' sobre las mismas imágenes base,\n",
    "# usamos índices fijos de un pequeño subset del train.\n",
    "\n",
    "\n",
    "indices = list(range(min(8, len(train_ds_plain))))\n",
    "\n",
    "subset_plain = Subset(train_ds_plain, indices)\n",
    "\n",
    "subset_aug   = Subset(train_ds_aug,   indices)\n",
    "\n",
    "\n",
    "\n",
    "plain_loader = DataLoader(subset_plain, batch_size=4, shuffle=False)\n",
    "\n",
    "aug_loader   = DataLoader(subset_aug,   batch_size=4, shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "def denormalize(img_tensor, mean, std):\n",
    "\n",
    "    m = torch.tensor(mean).view(3,1,1)\n",
    "\n",
    "    s = torch.tensor(std).view(3,1,1)\n",
    "\n",
    "    return img_tensor * s + m\n",
    "\n",
    "\n",
    "\n",
    "# Mostrar un lote 'plain'\n",
    "images_p, labels_p = next(iter(plain_loader))\n",
    "images_a, labels_a = next(iter(aug_loader))\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(10, 5))\n",
    "\n",
    "fig.suptitle('Originales (arriba) vs Aumentadas (abajo)')\n",
    "\n",
    "\n",
    "\n",
    "# Fila 1: originales\n",
    "for i in range(images_p.size(0)):\n",
    "\n",
    "    ax = plt.subplot(2, images_p.size(0), i+1)\n",
    "\n",
    "    img = denormalize(images_p[i], mean, std).permute(1,2,0).numpy()\n",
    "\n",
    "    ax.imshow(np.clip(img, 0, 1))\n",
    "\n",
    "    ax.set_title(class_names[labels_p[i].item()])\n",
    "\n",
    "    ax.axis('off')\n",
    "\n",
    "\n",
    "\n",
    "# Fila 2: aumentadas\n",
    "for i in range(images_a.size(0)):\n",
    "\n",
    "    ax = plt.subplot(2, images_a.size(0), images_a.size(0) + i + 1)\n",
    "\n",
    "    img = denormalize(images_a[i], mean, std).permute(1,2,0).numpy()\n",
    "\n",
    "    ax.imshow(np.clip(img, 0, 1))\n",
    "\n",
    "    ax.axis('off')\n",
    "\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61747f80",
   "metadata": {},
   "source": [
    "## 5) Definición de la CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3714def",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "\n",
    "    \"\"\"CNN con ≥2 conv, pooling y FC. Uso de AdaptiveAvgPool2d para evitar cálculos manuales.\n",
    "\n",
    "    Entrada: (B, 3, 150, 150)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_classes):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.MaxPool2d(2),  # 150 -> 75\n",
    "\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.MaxPool2d(2),  # 75 -> 37\n",
    "\n",
    "\n",
    "            # Bloque extra opcional para mayor capacidad\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "        )\n",
    "\n",
    "        # Reducimos espacialmente a un tamaño fijo 4x4 para no depender exacto de 150x150\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((4,4))\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "\n",
    "            nn.Flatten(),\n",
    "\n",
    "            nn.Linear(128*4*4, 256),\n",
    "\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Dropout(p=0.3),\n",
    "\n",
    "            nn.Linear(256, num_classes)\n",
    "\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.features(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "\n",
    "        x = self.classifier(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "model = SimpleCNN(num_classes).to(DEVICE)\n",
    "\n",
    "model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d545a47",
   "metadata": {},
   "source": [
    "## 6) Entrenamiento (30 épocas) con aumentos y evaluación en test sin aumentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1970d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "\n",
    "EPOCHS = 30\n",
    "\n",
    "\n",
    "\n",
    "def train_one_epoch(model, loader, optimizer, criterion, device):\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    running_loss = 0.0\n",
    "\n",
    "    correct = 0\n",
    "\n",
    "    total = 0\n",
    "\n",
    "    for imgs, labels in loader:\n",
    "\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(imgs)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * imgs.size(0)\n",
    "\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        correct += (preds == labels).sum().item()\n",
    "\n",
    "        total += labels.size(0)\n",
    "\n",
    "    return running_loss/total, correct/total\n",
    "\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "\n",
    "def evaluate(model, loader, criterion, device):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    running_loss = 0.0\n",
    "\n",
    "    correct = 0\n",
    "\n",
    "    total = 0\n",
    "\n",
    "    for imgs, labels in loader:\n",
    "\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(imgs)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        running_loss += loss.item() * imgs.size(0)\n",
    "\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        correct += (preds == labels).sum().item()\n",
    "\n",
    "        total += labels.size(0)\n",
    "\n",
    "    return running_loss/total, correct/total\n",
    "\n",
    "\n",
    "\n",
    "history = { 'train_loss': [], 'train_acc': [], 'test_loss': [], 'test_acc': [] }\n",
    "\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "\n",
    "    tr_loss, tr_acc = train_one_epoch(model, train_loader, optimizer, criterion, DEVICE)\n",
    "\n",
    "    te_loss, te_acc = evaluate(model, test_loader, criterion, DEVICE)\n",
    "\n",
    "    history['train_loss'].append(tr_loss)\n",
    "\n",
    "    history['train_acc'].append(tr_acc)\n",
    "\n",
    "    history['test_loss'].append(te_loss)\n",
    "\n",
    "    history['test_acc'].append(te_acc)\n",
    "\n",
    "    print(f\"Epoch {epoch:02d}/{EPOCHS} | Train Loss: {tr_loss:.4f} Acc: {tr_acc:.4f} | Test Loss: {te_loss:.4f} Acc: {te_acc:.4f}\")\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(f\"Tiempo total: {end-start:.1f}s\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b800dfc2",
   "metadata": {},
   "source": [
    "## 7) Curvas de pérdida y precisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf45b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráficas (sin estilos ni colores específicos)\n",
    "\n",
    "epochs = range(1, EPOCHS+1)\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "\n",
    "plt.plot(epochs, history['train_loss'], label='Train Loss')\n",
    "\n",
    "plt.plot(epochs, history['test_loss'],  label='Test Loss')\n",
    "\n",
    "plt.xlabel('Época')\n",
    "\n",
    "plt.ylabel('Pérdida')\n",
    "\n",
    "plt.title('Pérdida durante entrenamiento/evaluación')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "\n",
    "plt.plot(epochs, history['train_acc'], label='Train Acc')\n",
    "\n",
    "plt.plot(epochs, history['test_acc'],  label='Test Acc')\n",
    "\n",
    "plt.xlabel('Época')\n",
    "\n",
    "plt.ylabel('Precisión')\n",
    "\n",
    "plt.title('Precisión durante entrenamiento/evaluación')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ecee366",
   "metadata": {},
   "source": [
    "## 8) Precisión final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8507eec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test_loss, final_test_acc = evaluate(model, test_loader, criterion, DEVICE)\n",
    "\n",
    "print({\n",
    "\n",
    "    'final_test_loss': round(final_test_loss, 4),\n",
    "\n",
    "    'final_test_acc' : round(final_test_acc, 4)\n",
    "\n",
    "})\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}

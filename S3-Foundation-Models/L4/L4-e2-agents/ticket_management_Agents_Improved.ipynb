{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12d2ac78",
   "metadata": {},
   "source": [
    "\n",
    "#  EduFlowTech — Multi‑Agent Workflow with LangChain (Improved)\n",
    "\n",
    "This notebook implements a **three‑agent workflow** for ticket management in a fictional e‑learning company.  \n",
    "\n",
    "##  Learning goals\n",
    "- Build a modular, multi‑agent system with LangChain (Query Processor → Content Searcher → Response Generator).\n",
    "- Query a **simulated course/lesson database** with `pandas`.\n",
    "- Coordinate agents with a clear, reproducible **workflow**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc50acf",
   "metadata": {},
   "source": [
    "\n",
    "## 1) Setup & Imports\n",
    "\n",
    "We import the libraries, set a **fake OpenAI API key**, and prepare optional LangChain components.  \n",
    "> Note: We include deterministic fallbacks to keep the notebook runnable without real API calls.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4660ac96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment ready. Fake LLM available: True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Core\n",
    "import os\n",
    "import json\n",
    "import textwrap\n",
    "import pandas as pd\n",
    "\n",
    "# LangChain (modern imports; tools optional)\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "\n",
    "try:\n",
    "    from langchain_community.llms.fake import FakeListLLM  # works in modern LangChain\n",
    "    _HAS_FAKE_LLM = True\n",
    "except Exception:\n",
    "    _HAS_FAKE_LLM = False\n",
    "\n",
    "# Fictitious OpenAI API key as required by the brief\n",
    "import openai\n",
    "openai.api_key = \"sk-YOUR_FAKE_API_KEY\"\n",
    "\n",
    "print(\"Environment ready. Fake LLM available:\", _HAS_FAKE_LLM)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc866448",
   "metadata": {},
   "source": [
    "\n",
    "## 2) Simulated EduFlowTech Database\n",
    "\n",
    "We enrich the dataset so the system can answer a wider variety of queries.  \n",
    "Columns: `course`, `topic`, `lesson`, `exercise`, `level`, `link`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f67b371",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 34\u001b[39m\n\u001b[32m      1\u001b[39m data = {\n\u001b[32m      2\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcourse\u001b[39m\u001b[33m\"\u001b[39m: [\n\u001b[32m      3\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mBasic Deep Learning\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mPython for AI\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mComputer Vision\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mNatural Language Processing\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     31\u001b[39m     ]\n\u001b[32m     32\u001b[39m }\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m df = \u001b[43mpd\u001b[49m.DataFrame(data)\n\u001b[32m     35\u001b[39m df\n",
      "\u001b[31mNameError\u001b[39m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "data = {\n",
    "    \"course\": [\n",
    "        \"Basic Deep Learning\", \"Python for AI\", \"Computer Vision\", \"Natural Language Processing\",\n",
    "        \"MLOps Foundations\", \"Data Engineering Basics\", \"Reinforcement Learning Intro\", \"Advanced Deep Learning\"\n",
    "    ],\n",
    "    \"topic\": [\n",
    "        \"Neural Networks\", \"Python Programming\", \"Image Classification\", \"Text Analysis\",\n",
    "        \"MLOps & Deployment\", \"ETL & Pipelines\", \"Policy & Value Functions\", \"Transformers & Attention\"\n",
    "    ],\n",
    "    \"lesson\": [\n",
    "        \"Introduction to Neural Networks\", \"Loops and Functions\", \"Basic CNNs\", \"Embeddings and Transformers\",\n",
    "        \"Model Serving with FastAPI\", \"Building ETL with Airflow\", \"Q-Learning Essentials\", \"Efficient Attention Mechanisms\"\n",
    "    ],\n",
    "    \"exercise\": [\n",
    "        \"Implement a simple network\", \"Create a factorial function\", \"Classify cats and dogs\",\n",
    "        \"Translate a text using embeddings\", \"Deploy a model endpoint\", \"Create an Airflow DAG\",\n",
    "        \"Implement epsilon-greedy\", \"Fine-tune a transformer\"\n",
    "    ],\n",
    "    \"level\": [\n",
    "        \"Intermediate\", \"Beginner\", \"Intermediate\", \"Advanced\", \"Intermediate\", \"Intermediate\", \"Intermediate\", \"Advanced\"\n",
    "    ],\n",
    "    \"link\": [\n",
    "        \"https://eduflowtech.com/deep-learning/intro-nn\",\n",
    "        \"https://eduflowtech.com/python/loops\",\n",
    "        \"https://eduflowtech.com/vision/cnn-basics\",\n",
    "        \"https://eduflowtech.com/nlp/embeddings-transformers\",\n",
    "        \"https://eduflowtech.com/mlops/fastapi-serving\",\n",
    "        \"https://eduflowtech.com/data/airflow-etl\",\n",
    "        \"https://eduflowtech.com/rl/q-learning\",\n",
    "        \"https://eduflowtech.com/deep/attention-efficiency\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e6a0f7",
   "metadata": {},
   "source": [
    "\n",
    "## 3) Utilities & Robust Search\n",
    "\n",
    "We ensure results are **never empty**: ambiguous queries fall back to a reasonable default.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0352a4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _non_empty(df_like: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Return at least one row to keep the system responsive.\"\"\"\n",
    "    if df_like is None or df_like.empty:\n",
    "        return df.sample(1).reset_index(drop=True)\n",
    "    return df_like.reset_index(drop=True)\n",
    "\n",
    "def search_content(category: str, query: str) -> pd.DataFrame:\n",
    "    \"\"\"Heuristic content search across topics and lessons (always returns ≥1 row).\"\"\"\n",
    "    q = (query or \"\").lower()\n",
    "    # Map broad intents to topics\n",
    "    if any(k in q for k in [\"neural\", \"network\", \"nn\"]):\n",
    "        res = df[df[\"topic\"].str.contains(\"Neural\", case=False)]\n",
    "    elif \"python\" in q:\n",
    "        res = df[df[\"topic\"].str.contains(\"Python\", case=False)]\n",
    "    elif any(k in q for k in [\"image\", \"vision\", \"cnn\"]):\n",
    "        res = df[df[\"topic\"].str.contains(\"Image|Vision\", case=False, regex=True)]\n",
    "    elif any(k in q for k in [\"text\", \"nlp\", \"language\", \"embedding\", \"transformer\"]):\n",
    "        res = df[df[\"topic\"].str.contains(\"Text|Transformers\", case=False, regex=True)]\n",
    "    elif any(k in q for k in [\"mlops\", \"deploy\", \"serve\", \"production\"]):\n",
    "        res = df[df[\"topic\"].str.contains(\"MLOps\", case=False)]\n",
    "    elif any(k in q for k in [\"etl\", \"pipeline\", \"airflow\", \"data engineering\"]):\n",
    "        res = df[df[\"topic\"].str.contains(\"ETL|Pipelines\", case=False, regex=True)]\n",
    "    elif any(k in q for k in [\"reinforcement\", \"q-learning\", \"policy\", \"value\"]):\n",
    "        res = df[df[\"topic\"].str.contains(\"Policy|Value|Reinforcement\", case=False, regex=True)]\n",
    "    elif any(k in q for k in [\"bug\", \"error\", \"crash\", \"exception\", \"traceback\"]):\n",
    "        # If it's a technical error, route to something practical like MLOps/Data Eng for triage\n",
    "        res = df[df[\"topic\"].str.contains(\"MLOps|ETL\", case=False, regex=True)]\n",
    "    else:\n",
    "        # Fallback: try fuzzy in lesson names, else sample\n",
    "        res = df[df[\"lesson\"].str.lower().str.contains(q)] if q else pd.DataFrame()\n",
    "    return _non_empty(res)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2693025c",
   "metadata": {},
   "source": [
    "\n",
    "## 4) Agent 1 — Query Processor\n",
    "\n",
    "**Goal:** classify the user query as `lesson`, `exercise`, or `technical error`.\n",
    "\n",
    "We provide:\n",
    "- A **LangChain `LLMChain`** (keeps the formal agent requirement), and\n",
    "- A **deterministic fallback classifier** (so the notebook runs without external APIs).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b01118f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "processor_prompt = PromptTemplate(\n",
    "    input_variables=[\"query\"],\n",
    "    template=textwrap.dedent(\"\"\"\n",
    "        You are a classifier for student queries. Categorize the query into exactly one of:\n",
    "        - lesson\n",
    "        - exercise\n",
    "        - technical error\n",
    "        \n",
    "        Query: {query}\n",
    "        \n",
    "        Category:\n",
    "    \"\"\")\n",
    ")\n",
    "\n",
    "if _HAS_FAKE_LLM:\n",
    "    # Returns 'lesson' deterministically for demo (you can extend the list to drive different flows)\n",
    "    processor_llm = FakeListLLM(responses=[\"lesson\"])\n",
    "    processor_agent = LLMChain(llm=processor_llm, prompt=processor_prompt)\n",
    "else:\n",
    "    processor_agent = None  # We'll rely on the heuristic fallback below.\n",
    "\n",
    "def classify_query(query: str) -> str:\n",
    "    \"\"\"Deterministic classifier to keep the notebook runnable offline.\"\"\"\n",
    "    q = (query or \"\").lower()\n",
    "    if any(k in q for k in [\"bug\", \"error\", \"crash\", \"exception\", \"traceback\"]):\n",
    "        return \"technical error\"\n",
    "    if any(k in q for k in [\"exercise\", \"task\", \"practice\", \"quiz\"]):\n",
    "        return \"exercise\"\n",
    "    # default\n",
    "    return \"lesson\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71af0882",
   "metadata": {},
   "source": [
    "\n",
    "## 5) Agent 2 — Content Searcher\n",
    "\n",
    "**Goal:** retrieve the most relevant content from the database.  \n",
    "We expose a simple **Python tool** (`search_content`) that other agents can call.\n",
    "\n",
    "> Optional: In a full LangChain agent loop you could wrap `search_content` as a `Tool` and\n",
    "> initialize an agent with `initialize_agent([...])`. We keep it lightweight and fully runnable here.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e1388a",
   "metadata": {},
   "source": [
    "\n",
    "## 6) Agent 3 — Response Generator\n",
    "\n",
    "**Goal:** produce a friendly, concise answer referencing the best‑fit lesson/exercise and link.\n",
    "\n",
    "We include:\n",
    "- A **LangChain `LLMChain`** (formal component), and\n",
    "- A **deterministic renderer** that formats the final message.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03f7d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "response_prompt = PromptTemplate(\n",
    "    input_variables=[\"query\", \"records\"],\n",
    "    template=textwrap.dedent(\"\"\"\n",
    "        You are EduFlowTech's assistant. Based on the retrieved records, write a concise, helpful reply.\n",
    "        \n",
    "        User query: {query}\n",
    "        \n",
    "        Records:\n",
    "        {records}\n",
    "        \n",
    "        Your reply should:\n",
    "        - Recommend the single best lesson/exercise.\n",
    "        - Include the link.\n",
    "        - Be friendly and actionable.\n",
    "    \"\"\")\n",
    ")\n",
    "\n",
    "if _HAS_FAKE_LLM:\n",
    "    # deterministic response sample\n",
    "    response_llm = FakeListLLM(responses=[\"Here is a recommended lesson with a link.\"])\n",
    "    response_agent = LLMChain(llm=response_llm, prompt=response_prompt)\n",
    "else:\n",
    "    response_agent = None\n",
    "\n",
    "def render_response(query: str, rec: pd.Series) -> str:\n",
    "    return (\n",
    "        f\"Recommended lesson for your query: **{rec['lesson']}** \"\n",
    "        f\"from the course **{rec['course']}** (level: {rec['level']}).\\n\"\n",
    "        f\"Topic: {rec['topic']}.\\n\"\n",
    "        f\"Link: {rec['link']}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ba6e0e",
   "metadata": {},
   "source": [
    "\n",
    "## 7) Visual Diagram — Agent Interaction\n",
    "\n",
    "### ASCII Diagram (no dependencies)\n",
    "```\n",
    "User Query\n",
    "    │\n",
    "    ▼\n",
    "[Agent 1: Query Processor]\n",
    "    │  category (lesson / exercise / technical error)\n",
    "    ▼\n",
    "[Agent 2: Content Searcher]\n",
    "    │  top‑K records (DataFrame rows)\n",
    "    ▼\n",
    "[Agent 3: Response Generator]\n",
    "    │  final message (with link)\n",
    "    ▼\n",
    "System Reply\n",
    "```\n",
    "\n",
    "> Optionally, if you have `graphviz` installed, run the next cell to render a flowchart.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69be7b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Optional: Graphviz diagram (safe to skip if not installed)\n",
    "try:\n",
    "    from graphviz import Digraph\n",
    "    dot = Digraph(comment=\"EduFlowTech Agents\")\n",
    "    dot.attr(rankdir=\"TB\", nodesep=\"0.4\", fontsize=\"10\")\n",
    "    dot.node(\"U\", \"User Query\")\n",
    "    dot.node(\"A1\", \"Agent 1:\\nQuery Processor\")\n",
    "    dot.node(\"A2\", \"Agent 2:\\nContent Searcher\")\n",
    "    dot.node(\"A3\", \"Agent 3:\\nResponse Generator\")\n",
    "    dot.node(\"R\", \"System Reply\")\n",
    "\n",
    "    dot.edges([\"UA1\"])\n",
    "    dot.edge(\"U\", \"A1\")\n",
    "    dot.edge(\"A1\", \"A2\", label=\"category\")\n",
    "    dot.edge(\"A2\", \"A3\", label=\"top‑K records\")\n",
    "    dot.edge(\"A3\", \"R\", label=\"final message\")\n",
    "\n",
    "    display(dot)\n",
    "except Exception as e:\n",
    "    print(\"Graphviz not available (skipping). Reason:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09619b3c",
   "metadata": {},
   "source": [
    "\n",
    "## 8) Orchestrator — End‑to‑End Workflow\n",
    "\n",
    "This function wires the three agents:\n",
    "1. **Agent 1** classifies the query.\n",
    "2. **Agent 2** fetches the best matching content.\n",
    "3. **Agent 3** composes the final reply.\n",
    "\n",
    "We also provide **multiple test scenarios** to showcase adaptability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4473d1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def workflow(query: str, k: int = 1) -> dict:\n",
    "    \"\"\"End‑to‑end coordination with deterministic fallbacks for full reproducibility.\"\"\"\n",
    "    # Agent 1 — get category\n",
    "    category = classify_query(query)\n",
    "    # Agent 2 — content search\n",
    "    results = search_content(category, query)\n",
    "    # select top-1 for a concise answer (you could extend to top‑k)\n",
    "    best = results.iloc[0]\n",
    "    # Agent 3 — final response\n",
    "    answer = render_response(query, best)\n",
    "    return {\n",
    "        \"category\": category,\n",
    "        \"results\": results.head(k).to_dict(orient=\"records\"),\n",
    "        \"answer\": answer\n",
    "    }\n",
    "\n",
    "tests = [\n",
    "    \"What is the best lesson to learn neural networks?\",\n",
    "    \"I need a Python exercise about loops\",\n",
    "    \"How do I deploy a model to production?\",\n",
    "    \"I got a crash error while running the training pipeline\",\n",
    "    \"Any intro to image classification with CNNs?\"\n",
    "]\n",
    "\n",
    "for q in tests:\n",
    "    out = workflow(q)\n",
    "    print(\"\\n---\")\n",
    "    print(\"Query:\", q)\n",
    "    print(\"Category:\", out[\"category\"])\n",
    "    print(\"Answer:\", out[\"answer\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

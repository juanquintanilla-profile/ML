{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dy8xvxFe7PwH"
   },
   "source": [
    "# Sesión práctica de estrategias de *prompting*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definamos algunas funciones auxiliares que necesitaremos durante el ejercicio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\juanq\\desktop\\repo\\.venv\\lib\\site-packages (4.57.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\juanq\\desktop\\repo\\.venv\\lib\\site-packages (from transformers) (3.20.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in c:\\users\\juanq\\desktop\\repo\\.venv\\lib\\site-packages (from transformers) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\juanq\\desktop\\repo\\.venv\\lib\\site-packages (from transformers) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\juanq\\desktop\\repo\\.venv\\lib\\site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\juanq\\desktop\\repo\\.venv\\lib\\site-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\juanq\\desktop\\repo\\.venv\\lib\\site-packages (from transformers) (2025.10.23)\n",
      "Requirement already satisfied: requests in c:\\users\\juanq\\desktop\\repo\\.venv\\lib\\site-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\juanq\\desktop\\repo\\.venv\\lib\\site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\juanq\\desktop\\repo\\.venv\\lib\\site-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\juanq\\desktop\\repo\\.venv\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\juanq\\desktop\\repo\\.venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\juanq\\desktop\\repo\\.venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\juanq\\desktop\\repo\\.venv\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\juanq\\desktop\\repo\\.venv\\lib\\site-packages (from requests->transformers) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\juanq\\desktop\\repo\\.venv\\lib\\site-packages (from requests->transformers) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\juanq\\desktop\\repo\\.venv\\lib\\site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\juanq\\desktop\\repo\\.venv\\lib\\site-packages (from requests->transformers) (2025.10.5)\n",
      "absl-py==2.3.1\n",
      "accelerate==1.11.0\n",
      "aiohappyeyeballs==2.6.1\n",
      "aiohttp==3.13.1\n",
      "aiosignal==1.4.0\n",
      "annotated-types==0.7.0\n",
      "anyio==4.11.0\n",
      "argon2-cffi==25.1.0\n",
      "argon2-cffi-bindings==25.1.0\n",
      "arrow==1.3.0\n",
      "asttokens==3.0.0\n",
      "astunparse==1.6.3\n",
      "async-lru==2.0.5\n",
      "attrs==25.4.0\n",
      "babel==2.17.0\n",
      "beautifulsoup4==4.14.2\n",
      "bleach==6.2.0\n",
      "blis==1.3.0\n",
      "catalogue==2.0.10\n",
      "certifi==2025.10.5\n",
      "cffi==2.0.0\n",
      "chardet==5.2.0\n",
      "charset-normalizer==3.4.4\n",
      "click==8.3.0\n",
      "cloudpathlib==0.23.0\n",
      "colorama==0.4.6\n",
      "comm==0.2.3\n",
      "confection==0.1.5\n",
      "contourpy==1.3.3\n",
      "cycler==0.12.1\n",
      "cymem==2.0.11\n",
      "datasets==4.3.0\n",
      "debugpy==1.8.17\n",
      "decorator==5.2.1\n",
      "defusedxml==0.7.1\n",
      "dill==0.4.0\n",
      "distro==1.9.0\n",
      "en_core_web_sm @ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl#sha256=1932429db727d4bff3deed6b34cfc05df17794f4a52eeb26cf8928f7c1a0fb85\n",
      "executing==2.2.1\n",
      "fastjsonschema==2.21.2\n",
      "filelock==3.20.0\n",
      "flatbuffers==25.9.23\n",
      "fonttools==4.60.1\n",
      "fqdn==1.5.1\n",
      "frozenlist==1.8.0\n",
      "fsspec==2025.9.0\n",
      "gast==0.6.0\n",
      "gensim==4.4.0\n",
      "google-pasta==0.2.0\n",
      "grpcio==1.75.1\n",
      "h11==0.16.0\n",
      "h5py==3.15.1\n",
      "httpcore==1.0.9\n",
      "httpx==0.28.1\n",
      "huggingface-hub==0.36.0\n",
      "idna==3.11\n",
      "ipykernel==7.0.1\n",
      "ipython==9.6.0\n",
      "ipython_pygments_lexers==1.1.1\n",
      "isoduration==20.11.0\n",
      "jedi==0.19.2\n",
      "Jinja2==3.1.6\n",
      "jiter==0.11.1\n",
      "joblib==1.5.2\n",
      "json5==0.12.1\n",
      "jsonpointer==3.0.0\n",
      "jsonschema==4.25.1\n",
      "jsonschema-specifications==2025.9.1\n",
      "jupyter-events==0.12.0\n",
      "jupyter-lsp==2.3.0\n",
      "jupyter_client==8.6.3\n",
      "jupyter_core==5.9.0\n",
      "jupyter_server==2.17.0\n",
      "jupyter_server_terminals==0.5.3\n",
      "jupyterlab==4.4.9\n",
      "jupyterlab_pygments==0.3.0\n",
      "jupyterlab_server==2.27.3\n",
      "kaggle==1.7.4.5\n",
      "kagglehub==0.3.13\n",
      "keras==3.12.0\n",
      "kiwisolver==1.4.9\n",
      "langcodes==3.5.0\n",
      "language_data==1.3.0\n",
      "lark==1.3.0\n",
      "libclang==18.1.1\n",
      "marisa-trie==1.3.1\n",
      "Markdown==3.9\n",
      "markdown-it-py==4.0.0\n",
      "MarkupSafe==3.0.3\n",
      "matplotlib==3.10.7\n",
      "matplotlib-inline==0.1.7\n",
      "mdurl==0.1.2\n",
      "mistune==3.1.4\n",
      "ml_dtypes==0.5.3\n",
      "mpmath==1.3.0\n",
      "multidict==6.7.0\n",
      "multiprocess==0.70.16\n",
      "murmurhash==1.0.13\n",
      "namex==0.1.0\n",
      "narwhals==2.8.0\n",
      "nbclient==0.10.2\n",
      "nbconvert==7.16.6\n",
      "nbformat==5.10.4\n",
      "nest-asyncio==1.6.0\n",
      "networkx==3.5\n",
      "nltk==3.9.2\n",
      "notebook==7.4.7\n",
      "notebook_shim==0.2.4\n",
      "numpy==2.2.6\n",
      "openai==2.7.1\n",
      "opencv-python==4.12.0.88\n",
      "opendatasets==0.1.22\n",
      "opt_einsum==3.4.0\n",
      "optree==0.17.0\n",
      "packaging==25.0\n",
      "pandas==2.3.3\n",
      "pandocfilters==1.5.1\n",
      "parso==0.8.5\n",
      "pillow==12.0.0\n",
      "platformdirs==4.5.0\n",
      "plotly==6.3.1\n",
      "preshed==3.0.10\n",
      "prometheus_client==0.23.1\n",
      "prompt_toolkit==3.0.52\n",
      "propcache==0.4.1\n",
      "protobuf==6.33.0\n",
      "psutil==7.1.0\n",
      "pure_eval==0.2.3\n",
      "pyarrow==22.0.0\n",
      "pycparser==2.23\n",
      "pydantic==2.12.3\n",
      "pydantic_core==2.41.4\n",
      "Pygments==2.19.2\n",
      "pyparsing==3.2.5\n",
      "python-dateutil==2.9.0.post0\n",
      "python-json-logger==4.0.0\n",
      "python-slugify==8.0.4\n",
      "pytz==2025.2\n",
      "pywinpty==3.0.2\n",
      "PyYAML==6.0.3\n",
      "pyzmq==27.1.0\n",
      "referencing==0.37.0\n",
      "regex==2025.10.23\n",
      "requests==2.32.5\n",
      "rfc3339-validator==0.1.4\n",
      "rfc3986-validator==0.1.1\n",
      "rfc3987-syntax==1.1.0\n",
      "rich==14.2.0\n",
      "rpds-py==0.27.1\n",
      "safetensors==0.6.2\n",
      "scikit-learn==1.7.2\n",
      "scipy==1.16.2\n",
      "seaborn==0.13.2\n",
      "Send2Trash==1.8.3\n",
      "setuptools==80.9.0\n",
      "shellingham==1.5.4\n",
      "six==1.17.0\n",
      "smart_open==7.4.1\n",
      "sniffio==1.3.1\n",
      "soupsieve==2.8\n",
      "spacy==3.8.7\n",
      "spacy-legacy==3.0.12\n",
      "spacy-loggers==1.0.5\n",
      "srsly==2.5.1\n",
      "stack-data==0.6.3\n",
      "sympy==1.14.0\n",
      "tensorboard==2.20.0\n",
      "tensorboard-data-server==0.7.2\n",
      "tensorflow==2.20.0\n",
      "termcolor==3.1.0\n",
      "terminado==0.18.1\n",
      "text-unidecode==1.3\n",
      "tf_keras==2.20.1\n",
      "thinc==8.3.6\n",
      "threadpoolctl==3.6.0\n",
      "tinycss2==1.4.0\n",
      "tokenizers==0.22.1\n",
      "torch==2.9.0\n",
      "torchaudio==2.9.0\n",
      "torchvision==0.24.0\n",
      "tornado==6.5.2\n",
      "tqdm==4.67.1\n",
      "traitlets==5.14.3\n",
      "transformers==4.57.1\n",
      "typer==0.20.0\n",
      "types-python-dateutil==2.9.0.20251008\n",
      "typing-inspection==0.4.2\n",
      "typing_extensions==4.15.0\n",
      "tzdata==2025.2\n",
      "uri-template==1.3.0\n",
      "urllib3==2.5.0\n",
      "wasabi==1.1.3\n",
      "wcwidth==0.2.14\n",
      "weasel==0.4.1\n",
      "webcolors==24.11.1\n",
      "webencodings==0.5.1\n",
      "websocket-client==1.9.0\n",
      "Werkzeug==3.1.3\n",
      "wheel==0.45.1\n",
      "wordcloud==1.9.4\n",
      "wrapt==1.17.3\n",
      "xxhash==3.6.0\n",
      "yarl==1.22.0\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip freeze ../../requierements.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7Dvq9oKIx_RU",
    "outputId": "766e40e0-f1e6-4d3b-eff8-e96996aa9e23"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TextStreamer, set_seed\n",
    "from transformers.generation.utils import GenerateDecoderOnlyOutput, GenerateBeamDecoderOnlyOutput\n",
    "import torch\n",
    "\n",
    "DEVICE = \"cpu\" # Si no tenéis GPU cambiar a \"cpu\"\n",
    "# Si usáis un Google Colab ó un entorno con GPU podéis dejarlo en \"cuda:0\"\n",
    "INSTRUCT_MODEL_CON_CASTELLANO = \"Qwen/Qwen2.5-0.5B-Instruct\" # ~2.4GB en la GPU\n",
    "model = AutoModelForCausalLM.from_pretrained(INSTRUCT_MODEL_CON_CASTELLANO).to(DEVICE)\n",
    "tokenizer = AutoTokenizer.from_pretrained(INSTRUCT_MODEL_CON_CASTELLANO)\n",
    "streamer = TextStreamer(tokenizer, skip_prompt=True, skip_special_tokens=True)\n",
    "\n",
    "\n",
    "def crear_prompt_chat_model(\n",
    "        mensaje_usuario: str,\n",
    "        tokenizer: AutoTokenizer,\n",
    "        historial: str = None,\n",
    "        mensaje_sistema: str = \"You are a helpful assistant.\"\n",
    ") -> str:\n",
    "\n",
    "    if historial is None:\n",
    "        messages = [{\"role\": \"system\", \"content\": mensaje_sistema}]\n",
    "    else:\n",
    "        messages = []\n",
    "\n",
    "    messages.append({\"role\": \"user\", \"content\": mensaje_usuario})\n",
    "    prompt = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "    if historial is not None:\n",
    "        prompt = f\"{historial} {prompt}\"\n",
    "    return prompt\n",
    "\n",
    "def responde_al_mensaje(\n",
    "        model: AutoModelForCausalLM,\n",
    "        tokenizer: AutoTokenizer,\n",
    "        prompt: str,\n",
    "        streamer: TextStreamer = None,\n",
    "        gen_kwargs: dict = None,\n",
    "        return_scores: bool = False,\n",
    "    ) -> list[str] | tuple[list[str], GenerateDecoderOnlyOutput]:\n",
    "\n",
    "    gen_kwargs = gen_kwargs or {}\n",
    "    if return_scores:\n",
    "        gen_kwargs[\"return_dict_in_generate\"] = True\n",
    "        gen_kwargs[\"output_scores\"] = True\n",
    "\n",
    "    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(DEVICE)\n",
    "\n",
    "    model_output = model.generate(\n",
    "        input_ids,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        **gen_kwargs,\n",
    "        streamer=streamer,\n",
    "    )\n",
    "    if isinstance(model_output, GenerateDecoderOnlyOutput):\n",
    "        # Será el caso si en model.generate hemos pasado return_dict_in_generate=True\n",
    "        response_tokens = model_output.sequences\n",
    "    elif isinstance(model_output, torch.Tensor):\n",
    "        response_tokens = model_output\n",
    "    elif isinstance(model_output, GenerateBeamDecoderOnlyOutput):\n",
    "        response_tokens = model_output.sequences\n",
    "    else:\n",
    "        raise ValueError(f\"El modelo ha devuelto un tipo inesperado: {type(model_output)}\")\n",
    "\n",
    "\n",
    "    responses_txt = tokenizer.batch_decode(response_tokens[:,len(input_ids[0]):], skip_special_tokens=True)\n",
    "\n",
    "    return responses_txt, model_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MWCQXTD37Pwp"
   },
   "source": [
    "## <a id='toc3_'></a>[Estrategias de *prompting*](#toc0_)\n",
    "\n",
    "Imaginemos que estamos desarrollando un software para un hospital, cuya función es procesar los emails y whatsapps que llegan solicitando\n",
    "cita, y extraer una serie de campos de forma estructurada para introducirlos en el sistema de gestión de citas.\n",
    "\n",
    "En concreto, queremos que el modelo extraiga la siguiente información:\n",
    "\n",
    " ```\n",
    "    {\n",
    "        \"fecha\": \"<fecha en formato dd/mm/aaaa>\",\n",
    "        \"hora\": \"<hora en formato hh:mm>\",\n",
    "        \"especialidad\": \"<especialidad>\",\n",
    "        \"doctor\": \"<nombre del doctor o doctora>\"\n",
    "    }\n",
    "\n",
    "```\n",
    "Indicaciones adicionales:\n",
    "* Si no se especifica algún campo, se debe incluir un string vacío \"\"\n",
    "* Si no especifica la fecha completa (ej. \"el viernes\"), se debe asumir la fecha del día más próximo que cumpla con sus condiciones\n",
    "* Si no se especifica la hora:\n",
    "  * Si se especifica mañana: asignarlo a las 10h\n",
    "  * Si se especifica tarde: asignarlo a las 18h\n",
    "  * Si no se especifica o se especifica algo sin sentido (ej. noche), dejarlo vacío\n",
    "\n",
    "Veamos como podemos usar distintas técnicas de prompting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "UmXqh6aj7Pwp"
   },
   "outputs": [],
   "source": [
    "# Ejemplos de \"test\" con los que trabajaremos\n",
    "mail_1 = \"\"\"Buenas, quería reservar cita a las 10h el 4 de abril con la ginecóloga Macarena García.\"\"\"\n",
    "mail_2= \"\"\"Hola!, tendríais una cita disponible el siguiente viernes por la tarde con algún traumatólogo?\"\"\"\n",
    "output_esperado_1 = {\n",
    "    \"fecha\": \"04/04/2025\",\n",
    "    \"hora\": \"10:00\",\n",
    "    \"especialidad\": \"ginecología\",\n",
    "    \"nombre\": \"Macarena García\"\n",
    "}\n",
    "output_esperado_2 = {\n",
    "    \"fecha\": \"31/01/2025\",\n",
    "    \"hora\": \"18:00\",\n",
    "    \"especialidad\": \"traumatología\",\n",
    "    \"doctor\": \"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xF7xOsmc7Pwp",
    "outputId": "99ad7da5-568f-41ae-ba40-4d4b698996e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "You are a helpful assistant.<|im_end|>\n",
      "<|im_start|>user\n",
      "\n",
      "Eres un asistente que gestiona citas en un centro médico. Recibes mails y tu función\n",
      "es extraer la siguiente información en un formato estructurado tipo:\n",
      "    {\n",
      "        \"fecha\": \"<fecha en formato dd/mm/aaaa>\",\n",
      "        \"hora\": \"<hora en formato hh:mm>\",\n",
      "        \"especialidad\": \"<especialidad>\",\n",
      "        \"doctor\": \"<nombre del doctor o doctora>\"\n",
      "    }\n",
      "Indicaciones adicionales:\n",
      "    - Si no se especifica algún campo, se debe incluir un string vacío \"\"\n",
      "    - Hoy es martes, 4 de noviembre de 2025\n",
      "    - Si no especifica la fecha completa, asume la fecha del día más próximo que cumpla con sus condiciones\n",
      "    - Si no se especifica la hora pero se especifica \"mañana\": asignarlo a las 10h\n",
      "    - Si no se especifica la hora pero se especifica \"tarde\": asignarlo a las 18h\n",
      "    - Si no se especifica o se especifica algo sin sentido (ej. noche), déjalo vacío\n",
      "\n",
      "Has recibido este mail:\n",
      "Buenas, quería reservar cita a las 10h el 4 de abril con la ginecóloga Macarena García.\n",
      "<|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Enfoque más directo\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "import locale\n",
    "# locale.setlocale(locale.LC_TIME, 'es_ES.UTF-8');\n",
    "\n",
    "# Set locale NO funciona en Google Colab, lo hacemos \"a mano\":\n",
    "dias_semana_str = {\n",
    "    0: \"lunes\",\n",
    "    1: \"martes\",\n",
    "    2: \"miércoles\",\n",
    "    3: \"jueves\",\n",
    "    4: \"viernes\",\n",
    "    5: \"sábado\",\n",
    "    6: \"domingo\"\n",
    "}\n",
    "meses_str = {\n",
    "    1: \"enero\",\n",
    "    2: \"febrero\",\n",
    "    3: \"marzo\",\n",
    "    4: \"abril\",\n",
    "    5: \"mayo\",\n",
    "    6: \"junio\",\n",
    "    7: \"julio\",\n",
    "    8: \"agosto\",\n",
    "    9: \"septiembre\",\n",
    "    10: \"octubre\",\n",
    "    11: \"noviembre\",\n",
    "    12: \"diciembre\"\n",
    "}\n",
    "\n",
    "\n",
    "def crear_prompt_chat_model_citas(mail: str, tokenizer: AutoTokenizer):\n",
    "    dia_str = dias_semana_str[datetime.today().weekday()]\n",
    "    mes_str = meses_str[datetime.today().month]\n",
    "    fecha_hoy_largo = f\"{dia_str}, {datetime.today().day} de {mes_str} de {datetime.today().year}\"\n",
    "    msj = f\"\"\"\n",
    "Eres un asistente que gestiona citas en un centro médico. Recibes mails y tu función\n",
    "es extraer la siguiente información en un formato estructurado tipo:\n",
    "    {{\n",
    "        \"fecha\": \"<fecha en formato dd/mm/aaaa>\",\n",
    "        \"hora\": \"<hora en formato hh:mm>\",\n",
    "        \"especialidad\": \"<especialidad>\",\n",
    "        \"doctor\": \"<nombre del doctor o doctora>\"\n",
    "    }}\n",
    "Indicaciones adicionales:\n",
    "    - Si no se especifica algún campo, se debe incluir un string vacío \"\"\n",
    "    - Hoy es {fecha_hoy_largo}\n",
    "    - Si no especifica la fecha completa, asume la fecha del día más próximo que cumpla con sus condiciones\n",
    "    - Si no se especifica la hora pero se especifica \"mañana\": asignarlo a las 10h\n",
    "    - Si no se especifica la hora pero se especifica \"tarde\": asignarlo a las 18h\n",
    "    - Si no se especifica o se especifica algo sin sentido (ej. noche), déjalo vacío\n",
    "\n",
    "Has recibido este mail:\n",
    "{mail}\n",
    "\"\"\"\n",
    "    prompt = crear_prompt_chat_model(msj, tokenizer)\n",
    "    return prompt\n",
    "\n",
    "prompt = crear_prompt_chat_model_citas(mail_1, tokenizer)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JPv2AuVQ7Pwq",
    "outputId": "ba53f5c5-232b-4d27-9dec-4d8274a7eef6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "    \"fecha\": \"04/04/2025\",\n",
      "    \"hora\": \"10:00\",\n",
      "    \"especialidad\": \"\",\n",
      "    \"doctor\": \"Macarena García\"\n",
      "}\n",
      "```\n",
      "\n",
      "Este formato proporciona una estructura clara para el contenido de la cita, asegurándote de que todos los campos sean completos y útiles.\n",
      "------------------------------\n",
      "```json\n",
      "{\n",
      "    \"fecha\": \"03/11/2025\",\n",
      "    \"hora\": \"17:00\",\n",
      "    \"especialidad\": \"Traumatología\",\n",
      "    \"doctor\": \"Nombre del Traumatólogo\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# Veamos el resultado\n",
    "SEED = 123\n",
    "set_seed(SEED)\n",
    "gen_kwargs = {\"max_new_tokens\": 100, \"temperature\": 0.5}\n",
    "response, model_output = responde_al_mensaje(model, tokenizer, crear_prompt_chat_model_citas(mail_1, tokenizer), streamer=streamer, gen_kwargs=gen_kwargs)\n",
    "print(\"-\"*30)\n",
    "response, model_output = responde_al_mensaje(model, tokenizer, crear_prompt_chat_model_citas(mail_2, tokenizer), streamer=streamer, gen_kwargs=gen_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IcDhk1rY7Pwq",
    "outputId": "be1c4e70-d5bb-4501-83e7-29e879da56f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "You are a helpful assistant.<|im_end|>\n",
      "<|im_start|>user\n",
      "\n",
      "Eres un asistente que gestiona citas en un centro médico. Recibes mails y tu función\n",
      "es extraer la siguiente información en un formato estructurado tipo:\n",
      "    {\n",
      "        \"fecha\": \"<fecha en formato dd/mm/aaaa>\",\n",
      "        \"hora\": \"<hora en formato hh:mm>\",\n",
      "        \"especialidad\": \"<especialidad>\",\n",
      "        \"doctor\": \"<nombre del doctor o doctora>\"\n",
      "    }\n",
      "Indicaciones adicionales:\n",
      "    - Si no se especifica algún campo, se debe incluir un string vacío \"\"\n",
      "    - Hoy es martes, 4 de noviembre de 2025\n",
      "    - Si no especifica la fecha completa, asume la fecha del día más próximo que\n",
      "        cumpla con sus condiciones\n",
      "    - Si no se especifica la hora pero se especifica \"mañana\": asignarlo a las 10h\n",
      "    - Si no se especifica la hora pero se especifica \"tarde\": asignarlo a las 18h\n",
      "    - Si no se especifica o se especifica algo sin sentido (ej. noche), déjalo vacío\n",
      "\n",
      "Completa la respuesta para el último mail de este mensaje:\n",
      "\n",
      "mail: Necesito una cita para el dentista con el Dr. Luis Molina a las 8h del próximo miércoles.\n",
      "respuesta: {\n",
      "    \"fecha\": \"05/11/2025\",\n",
      "    \"hora\": \"08:00\",\n",
      "    \"especialidad\": \"odontología\",\n",
      "    \"doctor\": \"Dr. Luis Molina\"\n",
      "}\n",
      "\n",
      "mail: ¿Podrían agendarme con la dermatóloga Clara Ruiz el 30 de este mes a las 3 de la tarde?\n",
      "respuesta: {\n",
      "    \"fecha\": \"30/11/2025\",\n",
      "    \"hora\": \"15:00\",\n",
      "    \"especialidad\": \"dermatólogía\",\n",
      "    \"doctor\": \"Clara Ruiz\"\n",
      "}\n",
      "\n",
      "mail: Quiero una cita con cualquier pediatra el 22 por la tarde.\n",
      "respuesta: {\n",
      "    \"fecha\": \"22/11/2025\",\n",
      "    \"hora\": \"18:00\",\n",
      "    \"especialidad\": \"pediatría\",\n",
      "    \"doctor\": \"\"\n",
      "}\n",
      "\n",
      "mail: Me gustaría agendar una revisión con el cardiólogo el 15 de abril por la mañana. Preferentemente antes del mediodía.\n",
      "respuesta: {\n",
      "    \"fecha\": \"15/04/2025\",\n",
      "    \"hora\": \"10:00\",\n",
      "    \"especialidad\": \"cardiología\",\n",
      "    \"doctor\": \"\"\n",
      "}\n",
      "\n",
      "mail: Buenas, quería reservar cita a las 10h el 4 de abril con la ginecóloga Macarena García.\n",
      "respuesta: <|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def crear_prompt_chat_model_citas_few_shot(mail: str, tokenizer: AutoTokenizer):\n",
    "\n",
    "    # Algunos ejemplos necesitan ser dinámicos, ajustados a la fecha de hoy\n",
    "    año = datetime.today().year\n",
    "    dia_str = dias_semana_str[datetime.today().weekday()]\n",
    "    mes_str = meses_str[datetime.today().month]\n",
    "    fecha_hoy_largo = f\"{dia_str}, {datetime.today().day} de {mes_str} de {año}\"\n",
    "    dias_hasta_miércoles = (2 - datetime.today().weekday()) % 7\n",
    "    if dias_hasta_miércoles == 0:\n",
    "        dias_hasta_miércoles = 7\n",
    "    fecha_next_miercoles =  (datetime.today() + timedelta(days=dias_hasta_miércoles)).strftime('%d/%m/%Y')\n",
    "\n",
    "    _30_este_mes = datetime.today().replace(day=30).strftime('%d/%m/%Y')\n",
    "    _22_este_mes = datetime.today().replace(day=22)\n",
    "\n",
    "    if _22_este_mes < datetime.today():\n",
    "        next_22 = datetime.today().replace(day=22, month=datetime.today().month + 1).strftime('%d/%m/%Y')\n",
    "    else:\n",
    "        next_22 = _22_este_mes.strftime('%d/%m/%Y')\n",
    "\n",
    "    msj = f\"\"\"\n",
    "Eres un asistente que gestiona citas en un centro médico. Recibes mails y tu función\n",
    "es extraer la siguiente información en un formato estructurado tipo:\n",
    "    {{\n",
    "        \"fecha\": \"<fecha en formato dd/mm/aaaa>\",\n",
    "        \"hora\": \"<hora en formato hh:mm>\",\n",
    "        \"especialidad\": \"<especialidad>\",\n",
    "        \"doctor\": \"<nombre del doctor o doctora>\"\n",
    "    }}\n",
    "Indicaciones adicionales:\n",
    "    - Si no se especifica algún campo, se debe incluir un string vacío \"\"\n",
    "    - Hoy es {fecha_hoy_largo}\n",
    "    - Si no especifica la fecha completa, asume la fecha del día más próximo que\n",
    "        cumpla con sus condiciones\n",
    "    - Si no se especifica la hora pero se especifica \"mañana\": asignarlo a las 10h\n",
    "    - Si no se especifica la hora pero se especifica \"tarde\": asignarlo a las 18h\n",
    "    - Si no se especifica o se especifica algo sin sentido (ej. noche), déjalo vacío\n",
    "\n",
    "Completa la respuesta para el último mail de este mensaje:\n",
    "\n",
    "mail: Necesito una cita para el dentista con el Dr. Luis Molina a las 8h del próximo miércoles.\n",
    "respuesta: {{\n",
    "    \"fecha\": \"{fecha_next_miercoles}\",\n",
    "    \"hora\": \"08:00\",\n",
    "    \"especialidad\": \"odontología\",\n",
    "    \"doctor\": \"Dr. Luis Molina\"\n",
    "}}\n",
    "\n",
    "mail: ¿Podrían agendarme con la dermatóloga Clara Ruiz el 30 de este mes a las 3 de la tarde?\n",
    "respuesta: {{\n",
    "    \"fecha\": \"{_30_este_mes}\",\n",
    "    \"hora\": \"15:00\",\n",
    "    \"especialidad\": \"dermatólogía\",\n",
    "    \"doctor\": \"Clara Ruiz\"\n",
    "}}\n",
    "\n",
    "mail: Quiero una cita con cualquier pediatra el 22 por la tarde.\n",
    "respuesta: {{\n",
    "    \"fecha\": \"{next_22}\",\n",
    "    \"hora\": \"18:00\",\n",
    "    \"especialidad\": \"pediatría\",\n",
    "    \"doctor\": \"\"\n",
    "}}\n",
    "\n",
    "mail: Me gustaría agendar una revisión con el cardiólogo el 15 de abril por la mañana. Preferentemente antes del mediodía.\n",
    "respuesta: {{\n",
    "    \"fecha\": \"15/04/{año}\",\n",
    "    \"hora\": \"10:00\",\n",
    "    \"especialidad\": \"cardiología\",\n",
    "    \"doctor\": \"\"\n",
    "}}\n",
    "\n",
    "mail: {mail}\n",
    "respuesta: \"\"\"\n",
    "    prompt = crear_prompt_chat_model(msj, tokenizer)\n",
    "    return prompt\n",
    "\n",
    "print(crear_prompt_chat_model_citas_few_shot(mail_1, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "muIgYs7N7Pwr",
    "outputId": "8344156c-9a94-472f-f4d2-e24804c6fefe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"fecha\": \"04/04/2025\",\n",
      "    \"hora\": \"10:00\",\n",
      "    \"especialidad\": \"ginecología\",\n",
      "    \"doctor\": \"Macarena García\"\n",
      "}\n",
      "------------------------------\n",
      "{\n",
      "    \"fecha\": \"16/11/2025\",\n",
      "    \"hora\": \"17:00\",\n",
      "    \"especialidad\": \"traumatología\",\n",
      "    \"doctor\": \"N/A\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "set_seed(SEED)\n",
    "gen_kwargs = {\"max_new_tokens\": 100, \"temperature\": 0.5}\n",
    "response, model_output = responde_al_mensaje(model, tokenizer, crear_prompt_chat_model_citas_few_shot(mail_1, tokenizer), streamer=streamer, gen_kwargs=gen_kwargs, return_scores=True)\n",
    "print(\"-\"*30)\n",
    "response, model_output = responde_al_mensaje(model, tokenizer, crear_prompt_chat_model_citas_few_shot(mail_2, tokenizer), streamer=streamer, gen_kwargs=gen_kwargs, return_scores=True)\n",
    "# inspeccionar_probabilidades(model_output, response, tokenizer, top_n_probables=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UK-YaliT7Pwr",
    "outputId": "1d183921-7647-4040-8a4f-72a3fe720c17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "You are a helpful assistant.<|im_end|>\n",
      "<|im_start|>user\n",
      "\n",
      "    Eres un asistente que gestiona citas en un centro médico. Recibes e-mails y tu función\n",
      "    es extraer la siguiente información en un formato estructurado tipo:\n",
      "        {\n",
      "            \"fecha\": \"<fecha en formato dd/mm/aaaa>\",\n",
      "            \"hora\": \"<hora en formato hh:mm>\",\n",
      "            \"especialidad\": \"<especialidad>\",\n",
      "            \"doctor\": \"<nombre del doctor o doctora>\"\n",
      "        }\n",
      "    Indicaciones adicionales:\n",
      "        - Si no se especifica algún campo, se debe incluir un string vacío \"\"\n",
      "        - Hoy es martes, 4 de noviembre de 2025\n",
      "        - Si no especifica la fecha completa, asume la fecha del día más próximo que\n",
      "          cumpla con sus condiciones\n",
      "        - Si no se especifica la hora pero se especifica \"mañana\": asignarlo a las 10h\n",
      "        - Si no se especifica la hora pero se especifica \"tarde\": asignarlo a las 18h\n",
      "        - Si no se especifica o se especifica algo sin sentido (ej. noche), déjalo vacío\n",
      "        - Antes de dar una respuesta, tienes que pensar paso a paso\n",
      "\n",
      "    Piensa la respuesta paso a paso para el último mail de este mensaje:\n",
      "\n",
      "    mail: Necesito una cita para el dentista con el Dr. Luis Molina a las 8h del próximo miércoles.\n",
      "    piensa la respuesta paso a paso:\n",
      "        -fecha: dice el próximo miércoles, hoy es martes, quedan 1 días hasta el próximo miércoles. Por lo que la fecha será 04/11/2025 + 1 días: \"05/11/2025\"\n",
      "        -hora: las 8h en formato HH:MM son las \"08:00\"\n",
      "        -especialidad: se menciona explícitamente \"dentista\", un dentista pertence a la rama de la \"odontología\"\n",
      "        -doctor: se menciona explícitamente \"Dr. Luis Molina\"\n",
      "    por tanto, la respuesta es: {\n",
      "    \"fecha\": \"05/11/2025\",\n",
      "    \"hora\": \"08:00\",\n",
      "    \"especialidad\": \"odontología\",\n",
      "    \"doctor\": \"Dr. Luis Molina\"\n",
      "    }\n",
      "\n",
      "    mail: Quiero una cita con cualquier pediatra el 22 por la tarde.\n",
      "    piensa la respuesta paso a paso:\n",
      "        -fecha: hoy es 04/11/2025, el siguiente 22 será el \"22/11/2025\"\n",
      "        -hora: no menciona una hora, pero menciona \"tarde\", así que, como dicen las instrucciones, la hora será \"18:00\"\n",
      "        -especialidad: se especifica \"pediatra\", por lo que la especialidad es \"pediatría\"\n",
      "        -doctor: no se menciona ningún doctor, por lo que el campo es un string vacío \"\"\n",
      "    por tanto, la respuesta es: {\n",
      "    \"fecha\": \"22/11/2025\",\n",
      "    \"hora\": \"11:30\",\n",
      "    \"especialidad\": \"pediatría\",\n",
      "    \"doctor\": \"\"\n",
      "    }\n",
      "\n",
      "    mail: Me gustaría agendar una revisión con el cardiólogo el 15 de abril por la mañana. Preferentemente antes del mediodía.\n",
      "    piensa la respuesta paso a paso:\n",
      "        -fecha: la fecha es el 15 de abril, no dice año pero como estamos en 2025, la fecha será \"15/04/2025\"\n",
      "        -hora: pno menciona una hora, pero menciona \"mañana\", así que, como dicen las instrucciones, la hora será \"10:00\"\n",
      "        -especialidad: se especifica \"cardiólogo\", por lo que la especialidad es \"cardiología\"\n",
      "        -doctor: no se menciona ningún doctor, por lo que el campo es un string vacío \"\"\n",
      "    por tanto, la respuesta es: {\n",
      "    \"fecha\": \"15/04/2025\",\n",
      "    \"hora\": \"11:00\",\n",
      "    \"especialidad\": \"cardiología\",\n",
      "    \"doctor\": \"\"\n",
      "    }\n",
      "\n",
      "    mail: Buenas, quería reservar cita a las 10h el 4 de abril con la ginecóloga Macarena García.\n",
      "    piensa paso a paso:<|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Chain of thought\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "def crear_prompt_chat_model_citas_cot(mail: str, tokenizer):\n",
    "\n",
    "    # Algunos ejemplos necesitan ser dinámicos, ajustados a la fecha de hoy\n",
    "    fecha_hoy_corto = datetime.today().strftime('%d/%m/%Y')\n",
    "    año = datetime.today().year\n",
    "    dia_str = dias_semana_str[datetime.today().weekday()]\n",
    "    mes_str = meses_str[datetime.today().month]\n",
    "    fecha_hoy_largo = f\"{dia_str}, {datetime.today().day} de {mes_str} de {año}\"\n",
    "    dias_hasta_miércoles = (2 - datetime.today().weekday()) % 7\n",
    "    if dias_hasta_miércoles == 0:\n",
    "        dias_hasta_miércoles = 7\n",
    "    fecha_next_miercoles =  (datetime.today() + timedelta(days=dias_hasta_miércoles)).strftime('%d/%m/%Y')\n",
    "\n",
    "    _22_este_mes = datetime.today().replace(day=22)\n",
    "\n",
    "    if _22_este_mes < datetime.today():\n",
    "        next_22 = datetime.today().replace(day=22, month=datetime.today().month + 1).strftime('%d/%m/%Y')\n",
    "    else:\n",
    "        next_22 = _22_este_mes.strftime('%d/%m/%Y')\n",
    "\n",
    "    msj = f\"\"\"\n",
    "    Eres un asistente que gestiona citas en un centro médico. Recibes e-mails y tu función\n",
    "    es extraer la siguiente información en un formato estructurado tipo:\n",
    "        {{\n",
    "            \"fecha\": \"<fecha en formato dd/mm/aaaa>\",\n",
    "            \"hora\": \"<hora en formato hh:mm>\",\n",
    "            \"especialidad\": \"<especialidad>\",\n",
    "            \"doctor\": \"<nombre del doctor o doctora>\"\n",
    "        }}\n",
    "    Indicaciones adicionales:\n",
    "        - Si no se especifica algún campo, se debe incluir un string vacío \"\"\n",
    "        - Hoy es {fecha_hoy_largo}\n",
    "        - Si no especifica la fecha completa, asume la fecha del día más próximo que\n",
    "          cumpla con sus condiciones\n",
    "        - Si no se especifica la hora pero se especifica \"mañana\": asignarlo a las 10h\n",
    "        - Si no se especifica la hora pero se especifica \"tarde\": asignarlo a las 18h\n",
    "        - Si no se especifica o se especifica algo sin sentido (ej. noche), déjalo vacío\n",
    "        - Antes de dar una respuesta, tienes que pensar paso a paso\n",
    "\n",
    "    Piensa la respuesta paso a paso para el último mail de este mensaje:\n",
    "\n",
    "    mail: Necesito una cita para el dentista con el Dr. Luis Molina a las 8h del próximo miércoles.\n",
    "    piensa la respuesta paso a paso:\n",
    "        -fecha: dice el próximo miércoles, hoy es {dia_str}, quedan {dias_hasta_miércoles} días hasta el próximo miércoles. Por lo que la fecha será {fecha_hoy_corto} + {dias_hasta_miércoles} días: \"{fecha_next_miercoles}\"\n",
    "        -hora: las 8h en formato HH:MM son las \"08:00\"\n",
    "        -especialidad: se menciona explícitamente \"dentista\", un dentista pertence a la rama de la \"odontología\"\n",
    "        -doctor: se menciona explícitamente \"Dr. Luis Molina\"\n",
    "    por tanto, la respuesta es: {{\n",
    "    \"fecha\": \"{fecha_next_miercoles}\",\n",
    "    \"hora\": \"08:00\",\n",
    "    \"especialidad\": \"odontología\",\n",
    "    \"doctor\": \"Dr. Luis Molina\"\n",
    "    }}\n",
    "\n",
    "    mail: Quiero una cita con cualquier pediatra el 22 por la tarde.\n",
    "    piensa la respuesta paso a paso:\n",
    "        -fecha: hoy es {fecha_hoy_corto}, el siguiente 22 será el \"{next_22}\"\n",
    "        -hora: no menciona una hora, pero menciona \"tarde\", así que, como dicen las instrucciones, la hora será \"18:00\"\n",
    "        -especialidad: se especifica \"pediatra\", por lo que la especialidad es \"pediatría\"\n",
    "        -doctor: no se menciona ningún doctor, por lo que el campo es un string vacío \"\"\n",
    "    por tanto, la respuesta es: {{\n",
    "    \"fecha\": \"{next_22}\",\n",
    "    \"hora\": \"11:30\",\n",
    "    \"especialidad\": \"pediatría\",\n",
    "    \"doctor\": \"\"\n",
    "    }}\n",
    "\n",
    "    mail: Me gustaría agendar una revisión con el cardiólogo el 15 de abril por la mañana. Preferentemente antes del mediodía.\n",
    "    piensa la respuesta paso a paso:\n",
    "        -fecha: la fecha es el 15 de abril, no dice año pero como estamos en {año}, la fecha será \"15/04/{año}\"\n",
    "        -hora: pno menciona una hora, pero menciona \"mañana\", así que, como dicen las instrucciones, la hora será \"10:00\"\n",
    "        -especialidad: se especifica \"cardiólogo\", por lo que la especialidad es \"cardiología\"\n",
    "        -doctor: no se menciona ningún doctor, por lo que el campo es un string vacío \"\"\n",
    "    por tanto, la respuesta es: {{\n",
    "    \"fecha\": \"15/04/{año}\",\n",
    "    \"hora\": \"11:00\",\n",
    "    \"especialidad\": \"cardiología\",\n",
    "    \"doctor\": \"\"\n",
    "    }}\n",
    "\n",
    "    mail: {mail}\n",
    "    piensa paso a paso:\"\"\"\n",
    "    prompt = crear_prompt_chat_model(msj, tokenizer)\n",
    "    return prompt\n",
    "\n",
    "print(crear_prompt_chat_model_citas_cot(mail_1, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "59AYZjQE7Pwr",
    "outputId": "5025cbbd-b666-45f5-83d8-f2456e5b6af3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- fecha: el día 4 de abril, ya que es el primer día de abril y no hay otro día disponible para esa hora.\n",
      "- hora: pno menciona una hora, pero la instrucción dice \"mañana\", así que, como dicen las instrucciones, la hora será \"10:00\".\n",
      "- especialidad: se especifica \"ginecóloga\", por lo que la especialidad es \"ginecología\".\n",
      "- doctor: no se menciona ningún doctor, por lo que el campo es un string vacío \"\"\n",
      "por tanto, la respuesta es: {\n",
      "    \"fecha\": \"04/04/2025\",\n",
      "    \"hora\": \"10:00\",\n",
      "    \"especialidad\": \"ginecología\",\n",
      "    \"doctor\": \"\"\n",
      "}\n",
      "------------------------------\n",
      "- Fecha: Hoy es 06/11/2025, el siguiente viernes será el \"19/11/2025\"\n",
      "- Horas: No menciona horas específicas, pero según las instrucciones, la hora será \"17:00\" (siempre es preferible al mediodía)\n",
      "- Especialidad: Se menciona \"traumatólogo\", por lo que la especialidad es \"tratamiento de lesiones\"\n",
      "- Doctor: Menciona \"traumatólogo\", por lo que el campo es un string vacío \"\"\n",
      "- Respuesta: {\n",
      "    \"fecha\": \"19/11/2025\",\n",
      "    \"hora\": \"17:00\",\n",
      "    \"especialidad\": \"tratamiento de lesiones\",\n",
      "    \"doctor\": \"\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "set_seed(SEED)\n",
    "gen_kwargs = {\"max_new_tokens\": 300, \"temperature\": 0.5}\n",
    "response, model_output = responde_al_mensaje(model, tokenizer, crear_prompt_chat_model_citas_cot(mail_1, tokenizer), streamer=streamer, gen_kwargs=gen_kwargs)\n",
    "print(\"-\"*30)\n",
    "response, model_output = responde_al_mensaje(model, tokenizer, crear_prompt_chat_model_citas_cot(mail_2, tokenizer), streamer=streamer, gen_kwargs=gen_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "DeepLearningEnv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0ed8e06c21b04f19a73846520cb635f9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_168ad46c4f6a4313afbe76ca7fd3a7dd",
      "placeholder": "​",
      "style": "IPY_MODEL_e71568204b0c445ea71cd8d054898f68",
      "value": "barcenas-mistral-7b.Q6_K.gguf: 100%"
     }
    },
    "168ad46c4f6a4313afbe76ca7fd3a7dd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2df62079697941a1b8c0cc2144fd5eb5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4d43b46d29254373872a97418f7745dc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0ed8e06c21b04f19a73846520cb635f9",
       "IPY_MODEL_e9a5c191cfb7478ebc8dff328b4f6bac",
       "IPY_MODEL_d89b1b19c5a24d64a5e2ac53649a09fc"
      ],
      "layout": "IPY_MODEL_a04b0866b213454b8308460b851dd6e1"
     }
    },
    "4fde216595e84eaba7004f18eaea6c8b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a04b0866b213454b8308460b851dd6e1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a61f9ffeb0d0486e82e70ba1293fa4a1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b2ee653d63ee41708d4080f0ee2d0251": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d89b1b19c5a24d64a5e2ac53649a09fc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a61f9ffeb0d0486e82e70ba1293fa4a1",
      "placeholder": "​",
      "style": "IPY_MODEL_4fde216595e84eaba7004f18eaea6c8b",
      "value": " 5.94G/5.94G [01:39&lt;00:00, 39.8MB/s]"
     }
    },
    "e71568204b0c445ea71cd8d054898f68": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e9a5c191cfb7478ebc8dff328b4f6bac": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b2ee653d63ee41708d4080f0ee2d0251",
      "max": 5942064768,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2df62079697941a1b8c0cc2144fd5eb5",
      "value": 5942064768
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c60461c7",
   "metadata": {},
   "source": [
    "# S2 - L3 - E1 / Life Expectancy prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b24f7dd",
   "metadata": {},
   "source": [
    "In this exercise, I will create a feed-forward neural network using PyTorch to solve a regression problem. The goal is to predict the life expectancy of different countries using various features such as Gross Domestic Product (GDP), health expenditure, adult mortality, access to education, and others. You will use a dataset provided by the World Health Organization (WHO) available on Kaggle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e04d09",
   "metadata": {},
   "source": [
    "### 1. Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47ff800",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from  torch.utils.data import DataLoader,Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5045940",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41737635",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Year</th>\n",
       "      <th>Status</th>\n",
       "      <th>Life expectancy</th>\n",
       "      <th>Adult Mortality</th>\n",
       "      <th>infant deaths</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>percentage expenditure</th>\n",
       "      <th>Hepatitis B</th>\n",
       "      <th>Measles</th>\n",
       "      <th>...</th>\n",
       "      <th>Polio</th>\n",
       "      <th>Total expenditure</th>\n",
       "      <th>Diphtheria</th>\n",
       "      <th>HIV/AIDS</th>\n",
       "      <th>GDP</th>\n",
       "      <th>Population</th>\n",
       "      <th>thinness  1-19 years</th>\n",
       "      <th>thinness 5-9 years</th>\n",
       "      <th>Income composition of resources</th>\n",
       "      <th>Schooling</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2015</td>\n",
       "      <td>Developing</td>\n",
       "      <td>65.0</td>\n",
       "      <td>263.0</td>\n",
       "      <td>62</td>\n",
       "      <td>0.01</td>\n",
       "      <td>71.279624</td>\n",
       "      <td>65.0</td>\n",
       "      <td>1154</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.16</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>584.259210</td>\n",
       "      <td>33736494.0</td>\n",
       "      <td>17.2</td>\n",
       "      <td>17.3</td>\n",
       "      <td>0.479</td>\n",
       "      <td>10.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2014</td>\n",
       "      <td>Developing</td>\n",
       "      <td>59.9</td>\n",
       "      <td>271.0</td>\n",
       "      <td>64</td>\n",
       "      <td>0.01</td>\n",
       "      <td>73.523582</td>\n",
       "      <td>62.0</td>\n",
       "      <td>492</td>\n",
       "      <td>...</td>\n",
       "      <td>58.0</td>\n",
       "      <td>8.18</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>612.696514</td>\n",
       "      <td>327582.0</td>\n",
       "      <td>17.5</td>\n",
       "      <td>17.5</td>\n",
       "      <td>0.476</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2013</td>\n",
       "      <td>Developing</td>\n",
       "      <td>59.9</td>\n",
       "      <td>268.0</td>\n",
       "      <td>66</td>\n",
       "      <td>0.01</td>\n",
       "      <td>73.219243</td>\n",
       "      <td>64.0</td>\n",
       "      <td>430</td>\n",
       "      <td>...</td>\n",
       "      <td>62.0</td>\n",
       "      <td>8.13</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>631.744976</td>\n",
       "      <td>31731688.0</td>\n",
       "      <td>17.7</td>\n",
       "      <td>17.7</td>\n",
       "      <td>0.470</td>\n",
       "      <td>9.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2012</td>\n",
       "      <td>Developing</td>\n",
       "      <td>59.5</td>\n",
       "      <td>272.0</td>\n",
       "      <td>69</td>\n",
       "      <td>0.01</td>\n",
       "      <td>78.184215</td>\n",
       "      <td>67.0</td>\n",
       "      <td>2787</td>\n",
       "      <td>...</td>\n",
       "      <td>67.0</td>\n",
       "      <td>8.52</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>669.959000</td>\n",
       "      <td>3696958.0</td>\n",
       "      <td>17.9</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.463</td>\n",
       "      <td>9.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2011</td>\n",
       "      <td>Developing</td>\n",
       "      <td>59.2</td>\n",
       "      <td>275.0</td>\n",
       "      <td>71</td>\n",
       "      <td>0.01</td>\n",
       "      <td>7.097109</td>\n",
       "      <td>68.0</td>\n",
       "      <td>3013</td>\n",
       "      <td>...</td>\n",
       "      <td>68.0</td>\n",
       "      <td>7.87</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>63.537231</td>\n",
       "      <td>2978599.0</td>\n",
       "      <td>18.2</td>\n",
       "      <td>18.2</td>\n",
       "      <td>0.454</td>\n",
       "      <td>9.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Country  Year      Status  Life expectancy   Adult Mortality  \\\n",
       "0  Afghanistan  2015  Developing              65.0            263.0   \n",
       "1  Afghanistan  2014  Developing              59.9            271.0   \n",
       "2  Afghanistan  2013  Developing              59.9            268.0   \n",
       "3  Afghanistan  2012  Developing              59.5            272.0   \n",
       "4  Afghanistan  2011  Developing              59.2            275.0   \n",
       "\n",
       "   infant deaths  Alcohol  percentage expenditure  Hepatitis B  Measles   ...  \\\n",
       "0             62     0.01               71.279624         65.0      1154  ...   \n",
       "1             64     0.01               73.523582         62.0       492  ...   \n",
       "2             66     0.01               73.219243         64.0       430  ...   \n",
       "3             69     0.01               78.184215         67.0      2787  ...   \n",
       "4             71     0.01                7.097109         68.0      3013  ...   \n",
       "\n",
       "   Polio  Total expenditure  Diphtheria    HIV/AIDS         GDP  Population  \\\n",
       "0    6.0               8.16         65.0        0.1  584.259210  33736494.0   \n",
       "1   58.0               8.18         62.0        0.1  612.696514    327582.0   \n",
       "2   62.0               8.13         64.0        0.1  631.744976  31731688.0   \n",
       "3   67.0               8.52         67.0        0.1  669.959000   3696958.0   \n",
       "4   68.0               7.87         68.0        0.1   63.537231   2978599.0   \n",
       "\n",
       "    thinness  1-19 years   thinness 5-9 years  \\\n",
       "0                   17.2                 17.3   \n",
       "1                   17.5                 17.5   \n",
       "2                   17.7                 17.7   \n",
       "3                   17.9                 18.0   \n",
       "4                   18.2                 18.2   \n",
       "\n",
       "   Income composition of resources  Schooling  \n",
       "0                            0.479       10.1  \n",
       "1                            0.476       10.0  \n",
       "2                            0.470        9.9  \n",
       "3                            0.463        9.8  \n",
       "4                            0.454        9.5  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad450b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features:  22\n",
      "Number of samples:  2938\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of features: \", df.shape[1])\n",
    "print(\"Number of samples: \", df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6fb5c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Country', 'Year', 'Status', 'Life expectancy ', 'Adult Mortality',\n",
      "       'infant deaths', 'Alcohol', 'percentage expenditure', 'Hepatitis B',\n",
      "       'Measles ', ' BMI ', 'under-five deaths ', 'Polio', 'Total expenditure',\n",
      "       'Diphtheria ', ' HIV/AIDS', 'GDP', 'Population',\n",
      "       ' thinness  1-19 years', ' thinness 5-9 years',\n",
      "       'Income composition of resources', 'Schooling'],\n",
      "      dtype='object')\n",
      "Index(['Country', 'Year', 'Status', 'Life_expectancy', 'Adult_Mortality',\n",
      "       'infant_deaths', 'Alcohol', 'percentage_expenditure', 'Hepatitis_B',\n",
      "       'Measles', 'BMI', 'under-five_deaths', 'Polio', 'Total_expenditure',\n",
      "       'Diphtheria', 'HIV/AIDS', 'GDP', 'Population', 'thinness__1-19_years',\n",
      "       'thinness_5-9_years', 'Income_composition_of_resources', 'Schooling'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)\n",
    "df.columns = [c.strip().replace(\" \",\"_\") for c in df.columns]\n",
    "\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9edc40",
   "metadata": {},
   "source": [
    "Check null values in key columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766acf64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Country                              0\n",
       "Year                                 0\n",
       "Status                               0\n",
       "Life_expectancy                     10\n",
       "Adult_Mortality                     10\n",
       "infant_deaths                        0\n",
       "Alcohol                            194\n",
       "percentage_expenditure               0\n",
       "Hepatitis_B                        553\n",
       "Measles                              0\n",
       "BMI                                 34\n",
       "under-five_deaths                    0\n",
       "Polio                               19\n",
       "Total_expenditure                  226\n",
       "Diphtheria                          19\n",
       "HIV/AIDS                             0\n",
       "GDP                                448\n",
       "Population                         652\n",
       "thinness__1-19_years                34\n",
       "thinness_5-9_years                  34\n",
       "Income_composition_of_resources    167\n",
       "Schooling                          163\n",
       "dtype: int64"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c952daa3",
   "metadata": {},
   "source": [
    "Erease null values in key columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a367de24",
   "metadata": {},
   "outputs": [],
   "source": [
    "required_cols = [\n",
    "    \"BMI\", \"GDP\", \"Schooling\", \"Adult_Mortality\",\n",
    "    \"Income_composition_of_resources\", \"Life_expectancy\"\n",
    "]\n",
    "df = df.dropna(subset=required_cols).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37f2e44",
   "metadata": {},
   "source": [
    "Complete the rest of the columns missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d540c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Country                            0\n",
       "Year                               0\n",
       "Status                             0\n",
       "Life_expectancy                    0\n",
       "Adult_Mortality                    0\n",
       "infant_deaths                      0\n",
       "Alcohol                            0\n",
       "percentage_expenditure             0\n",
       "Hepatitis_B                        0\n",
       "Measles                            0\n",
       "BMI                                0\n",
       "under-five_deaths                  0\n",
       "Polio                              0\n",
       "Total_expenditure                  0\n",
       "Diphtheria                         0\n",
       "HIV/AIDS                           0\n",
       "GDP                                0\n",
       "Population                         0\n",
       "thinness__1-19_years               0\n",
       "thinness_5-9_years                 0\n",
       "Income_composition_of_resources    0\n",
       "Schooling                          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "imp = SimpleImputer(strategy=\"mean\")\n",
    "df[numeric_cols] = imp.fit_transform(df[numeric_cols])\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ba4132",
   "metadata": {},
   "source": [
    "### 2. Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59741dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2458, 5)\n",
      "(2458,)\n"
     ]
    }
   ],
   "source": [
    "y = df['Life_expectancy'].copy()\n",
    "desired_cols = [\"BMI\",\"GDP\",\"Schooling\",\"Adult_Mortality\",\"Income_composition_of_resources\"]\n",
    "x = df.drop('Life_expectancy', axis=1)\n",
    "x = df[desired_cols]\n",
    "\n",
    "print(x.shape)\n",
    "print(y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba38ad2",
   "metadata": {},
   "source": [
    "### 3.  Standarize variebles to speed up convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063431be",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train,y_test = train_test_split(x,y,test_size=0.15,shuffle=True)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140be6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,y_train,x_val,y_val = train_test_split(x_train,y_train,test_size=0.2,shuffle=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9875beda",
   "metadata": {},
   "source": [
    "### 4. Create Dataset Class and transform into tensors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733ea1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LifeDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = torch.tensor(x, dtype=torch.float32)\n",
    "        self.y = torch.tensor(np.array(y).astype(np.float32), dtype=torch.float32)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.x.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx],self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b75db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = LifeDataset(x_train,y_train)\n",
    "\n",
    "test_dataset = LifeDataset(x_test,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f74bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = LifeDataset(x_val,y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685d4421",
   "metadata": {},
   "source": [
    "### 5. Use Dataloaders to rearrange data in barches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61138830",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,num_workers=4) \n",
    "val_dataloader = DataLoader(val_dataset,batch_size=batch_size,shuffle=False,num_workers=4) \n",
    "test_dataloader = DataLoader(test_dataset,batch_size=batch_size,shuffle=False,num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7436dfc",
   "metadata": {},
   "source": [
    "### 6. Create model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e7c3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPRegressor(nn.Module):\n",
    "    def __init__(self, input_shape):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(input_shape,16)\n",
    "        self.fc2 = nn.Linear(16,32)\n",
    "        self.fc3 = nn.Linear(32,1)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = nn.ReLU(self.fc1(x))\n",
    "        x = nn.ReLU(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee4a670",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLPRegressor(input_shape = x.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162345f9",
   "metadata": {},
   "source": [
    "### 7. Define cost function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f9362b",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "weight_decay = 0.01\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr = learning_rate,weight_decay=weight_decay) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b53880",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "epochs = 400 # Especificar número de épocas\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate,weight_decay=0.01 ) # Especificar el optimizador con la tasa de aprendizaje y parametros del modelo\n",
    "loss_fn = nn.MSELoss() # Especificar la función de coste"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60615d9",
   "metadata": {},
   "source": [
    "### 8. Model Training and Evaluation functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d93c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,train_dataloader,optimizer,loss_fn):\n",
    "    model.train()\n",
    "    epoch_loss = 0 \n",
    "    for i_batch,(x_train,y_train) in enumerate(train_dataloader):\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        pred = model(x_train)\n",
    "\n",
    "        batch_loss = loss_fn(pred,y_train.reshape(-1,1))\n",
    "\n",
    "        batch_loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += batch_loss.item()\n",
    "\n",
    "    loss_train = epoch_loss / i_batch\n",
    "\n",
    "    return loss_train\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cce1491",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(model, val_dataloader, loss_fn):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for i_batch, (x_val, y_val) in enumerate(val_dataloader):\n",
    "            \n",
    "            predictions = model(x_val)\n",
    "\n",
    "            batch_loss = loss_fn(predictions, y_val.reshape(-1,1)) # Calcula el coste (función de coste con los valores reales y predichos)\n",
    "            \n",
    "            epoch_loss += batch_loss.item()\n",
    "    \n",
    "    loss_val = epoch_loss / i_batch\n",
    "    \n",
    "    return loss_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d938a29",
   "metadata": {},
   "source": [
    "### 9. Training and validation loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef56f7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def training_evaluation_loop(epochs, model, train_dataloader, val_dataloader, optimizer, loss_fn):\n",
    "    # Empty loss and accuracy lists to track values\n",
    "    start = time.time()\n",
    "\n",
    "    loss_values_train = []\n",
    "    loss_values_val = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        loss_train = train(model, train_dataloader, optimizer, loss_fn) # Llama la función para el entrenamiento \n",
    "        loss_values_train.append(loss_train)\n",
    "\n",
    "        loss_val = evaluation(model, val_dataloader, loss_fn) # Llama la función para la evaluación\n",
    "        loss_values_val.append(loss_val)\n",
    "\n",
    "        \n",
    "\n",
    "        # Imprime cada 10 épocas loss_train y loss_val\n",
    "        \n",
    "    end = time.time()\n",
    "    total_time = end - start\n",
    "\n",
    "    print(f'Total training time: {total_time}')\n",
    "\n",
    "    return loss_values_train, loss_values_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61964c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictions(model,test_dataloader):\n",
    "\n",
    "    predictions = []\n",
    "    real_values = []\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x_test,y_test in test_dataloader:\n",
    "\n",
    "            outputs = model(x_test)\n",
    "            predictions.append(outputs.detach().cpu().np())\n",
    "            real_values.append(y_test.detach().cpu().np())\n",
    "    predictions = np.vstack(predictions)\n",
    "    real_values = np.hstack(real_values)\n",
    "    \n",
    "    # Calcula la métrica paa la regresión para ver el error entre los valores predichos y reales\n",
    "\n",
    "    # Imprima la métrica\n",
    "\n",
    "    return predictions, real_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d5b0b5",
   "metadata": {},
   "source": [
    "10. Train and test model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94dac3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3490db0",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 13664, 7452, 16852, 1444) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mEmpty\u001b[39m                                     Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\juanq\\Desktop\\repo\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1275\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._try_get_data\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m   1274\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1275\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data_queue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1276\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\multiprocessing\\queues.py:114\u001b[39m, in \u001b[36mQueue.get\u001b[39m\u001b[34m(self, block, timeout)\u001b[39m\n\u001b[32m    113\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._poll(timeout):\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[32m    115\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._poll():\n",
      "\u001b[31mEmpty\u001b[39m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[137]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m EPOCHS = \u001b[32m100\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m train_losses, val_losses = \u001b[43mtraining_evaluation_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloss_fn\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[134]\u001b[39m\u001b[32m, line 12\u001b[39m, in \u001b[36mtraining_evaluation_loop\u001b[39m\u001b[34m(epochs, model, train_dataloader, val_dataloader, optimizer, loss_fn)\u001b[39m\n\u001b[32m      8\u001b[39m loss_values_val = []\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m     loss_train = \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Llama la función para el entrenamiento \u001b[39;00m\n\u001b[32m     13\u001b[39m     loss_values_train.append(loss_train)\n\u001b[32m     15\u001b[39m     loss_val = evaluation(model, val_dataloader, loss_fn) \u001b[38;5;66;03m# Llama la función para la evaluación\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[132]\u001b[39m\u001b[32m, line 4\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(model, train_dataloader, optimizer, loss_fn)\u001b[39m\n\u001b[32m      2\u001b[39m model.train()\n\u001b[32m      3\u001b[39m epoch_loss = \u001b[32m0\u001b[39m \n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpred\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\juanq\\Desktop\\repo\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:732\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    729\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    730\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    731\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m732\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    733\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    734\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    735\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    736\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    737\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    738\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\juanq\\Desktop\\repo\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1482\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1479\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._process_data(data, worker_id)\n\u001b[32m   1481\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._tasks_outstanding > \u001b[32m0\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1482\u001b[39m idx, data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1483\u001b[39m \u001b[38;5;28mself\u001b[39m._tasks_outstanding -= \u001b[32m1\u001b[39m\n\u001b[32m   1484\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable:\n\u001b[32m   1485\u001b[39m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\juanq\\Desktop\\repo\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1444\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._get_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1440\u001b[39m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[32m   1441\u001b[39m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[32m   1442\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1443\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1444\u001b[39m         success, data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1445\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[32m   1446\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\juanq\\Desktop\\repo\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1288\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._try_get_data\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m   1286\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(failed_workers) > \u001b[32m0\u001b[39m:\n\u001b[32m   1287\u001b[39m     pids_str = \u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m.join(\u001b[38;5;28mstr\u001b[39m(w.pid) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m failed_workers)\n\u001b[32m-> \u001b[39m\u001b[32m1288\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   1289\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDataLoader worker (pid(s) \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpids_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) exited unexpectedly\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1290\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m   1291\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, queue.Empty):\n\u001b[32m   1292\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[31mRuntimeError\u001b[39m: DataLoader worker (pid(s) 13664, 7452, 16852, 1444) exited unexpectedly"
     ]
    }
   ],
   "source": [
    "EPOCHS = 100\n",
    "\n",
    "\n",
    "train_losses, val_losses = training_evaluation_loop(\n",
    "    epochs=EPOCHS,\n",
    "    model=model,\n",
    "    train_dataloader=train_dataloader,\n",
    "    val_dataloader=val_dataloader,\n",
    "    optimizer=optimizer,\n",
    "    loss_fn=loss_fn\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2dbfee6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_losses' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[138]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      3\u001b[39m plt.figure(figsize=(\u001b[32m8\u001b[39m,\u001b[32m5\u001b[39m))\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m plt.plot(\u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(\u001b[43mtrain_losses\u001b[49m)+\u001b[32m1\u001b[39m), train_losses, label=\u001b[33m\"\u001b[39m\u001b[33mTrain MSE\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m plt.plot(\u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(val_losses)+\u001b[32m1\u001b[39m),   val_losses,   label=\u001b[33m\"\u001b[39m\u001b[33mVal MSE\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      6\u001b[39m plt.xlabel(\u001b[33m\"\u001b[39m\u001b[33mÉpoca\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'train_losses' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(range(1, len(train_losses)+1), train_losses, label=\"Train MSE\")\n",
    "plt.plot(range(1, len(val_losses)+1),   val_losses,   label=\"Val MSE\")\n",
    "plt.xlabel(\"Época\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.title(\"Curva de aprendizaje (MSE Train vs Val)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83557fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "model.eval()\n",
    "y_true, y_pred = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for xb, yb in test_dataloader:\n",
    "        xb = xb.to(DEVICE)\n",
    "        yb = yb.to(DEVICE)\n",
    "        preds = model(xb).cpu().numpy()\n",
    "        y_pred.append(preds)\n",
    "        y_true.append(yb.cpu().numpy())\n",
    "\n",
    "y_true = np.vstack(y_true).ravel()\n",
    "y_pred = np.vstack(y_pred).ravel()\n",
    "\n",
    "test_mse = mean_squared_error(y_true, y_pred)\n",
    "test_mae = mean_absolute_error(y_true, y_pred)\n",
    "test_r2  = r2_score(y_true, y_pred)\n",
    "\n",
    "print(\"======= Métricas en TEST =======\")\n",
    "print(f\"MSE : {test_mse:.4f}\")\n",
    "print(f\"MAE : {test_mae:.4f}\")\n",
    "print(f\"R²  : {test_r2:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

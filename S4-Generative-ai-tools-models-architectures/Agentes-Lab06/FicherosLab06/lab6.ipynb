{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ecd2a4e",
   "metadata": {},
   "source": [
    "## Agentes de IA generativa\n",
    "\n",
    "### ¿Que vamos a ver?\n",
    "\n",
    "\n",
    "Usando el framework agents SDK de openAI\n",
    "\n",
    "0. ¿Por que usar un framework?\n",
    "1. Creación de un agente simple con los MCP definidos anteriormente + human in the loop\n",
    "2. Añadimos un segundo agente mediante handover para hacer busquedas web\n",
    "    \n",
    "    2.1 Memoria a corto plazo y manejo del contexto.\n",
    "3. Partimos el agente en un sistema de agentes múltiples con un supervisor\n",
    "    \n",
    "    3.1 Handoffs vs Agent as a tool\n",
    "4. Añadimos un planificador inicial y paralelismo.\n",
    "5. Un vistazo a otros frameworks (langgraph, A2A, Semantic Kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61a2d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openai-agents\n",
    "%pip install --upgrade openai "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc74ab5e",
   "metadata": {},
   "source": [
    "Creamos un \"hola mundo\" con el sdk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86818b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import agents\n",
    "\n",
    "os.environ[\"AZURE_OPENAI_API_KEY\"]=\" \"\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"]=\" \"\n",
    "os.environ[\"OPENAI_API_VERSION\"]=\"2025-04-01-preview\"\n",
    "from agents import Agent, Runner\n",
    "client = openai.AsyncAzureOpenAI(api_key=os.environ[\"AZURE_OPENAI_API_KEY\"], api_version=os.environ[\"OPENAI_API_VERSION\"], azure_endpoint=os.environ[\"AZURE_OPENAI_ENDPOINT\"])\n",
    "azure_model = agents.OpenAIChatCompletionsModel(openai_client=client, model=\"gpt-5-mini\")\n",
    "\n",
    "agent = Agent(name=\"Assistant\", instructions=\"You are a helpful assistant\", model=azure_model)\n",
    "question = input(\"What do you want to know?\")\n",
    "result = await Runner.run(agent, question)\n",
    "print(result.final_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572a8ff7",
   "metadata": {},
   "source": [
    "Añadamos los mcps "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e335e428",
   "metadata": {},
   "source": [
    "Nota: Con esta configuración, la \"ñ\", da problemas. Hay que quitarla\n",
    "\n",
    "Nota 2: Añadimos observabilidad desde el principio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e3a069",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Currently retrying 1 failed export(s)\n"
     ]
    }
   ],
   "source": [
    "import logfire\n",
    "logfire.configure(token=\" \")\n",
    "logfire.instrument_openai_agents() \n",
    "from agents.mcp import MCPServer, MCPServerStreamableHttp\n",
    "async with  MCPServerStreamableHttp(\n",
    "    name = \"User Wallet\",\n",
    "    params = {\n",
    "    \"url\" : \"http://localhost:800/mcp/\"\n",
    "    }\n",
    ") as wallet_mcp:\n",
    "    agent = Agent(name=\"Assistant\", instructions=\"You are a helpful assistant\", model=azure_model, mcp_servers=[wallet_mcp])\n",
    "    question = input(\"What do you want to know?\")\n",
    "    result = await Runner.run(agent, question)\n",
    "    print(result.final_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1e6ea8",
   "metadata": {},
   "source": [
    "Añadimos el otro server y organizamos un poco el código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69452554",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_agents(mcp_servers, user_input):\n",
    "    for server in mcp_servers:\n",
    "        await server.connect()\n",
    "    agent = Agent(name=\"Assistant\", instructions=\"Eres un asistente financiero que puede hacer operaciones con el portafolio de un usuario\", model=azure_model, mcp_servers=mcp_servers)\n",
    "    result = await Runner.run(agent, user_input)\n",
    "    return result.final_output\n",
    "\n",
    "async def create_mcps():\n",
    "    server_list = []\n",
    "    async with MCPServerStreamableHttp(\n",
    "        name=\"User Wallet\",\n",
    "        params={\n",
    "            \"url\": \"http://localhost:800/mcp/\"\n",
    "        }\n",
    "    ) as wallet_mcp:\n",
    "        wallet_mcp.connect()\n",
    "        server_list.append(wallet_mcp)\n",
    "        async with MCPServerStreamableHttp(\n",
    "            name=\"Financial live data\",\n",
    "            params={\n",
    "                \"url\": \"http://localhost:8002/mcp/\"\n",
    "            }\n",
    "        ) as financial_mcp:\n",
    "            financial_mcp.connect()\n",
    "            server_list.append(financial_mcp)\n",
    "            return server_list\n",
    "\n",
    "async def main():\n",
    "    question = input(\"En que puedo ayudarte?\")\n",
    "    server_list = await create_mcps()\n",
    "    res = await run_agents(server_list, question)\n",
    "\n",
    "await main() #Nota, fuera de jupyter, se debe usar asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19c57cb",
   "metadata": {},
   "source": [
    "Vamos a añadir human in the loop y a meter un numero máximo de ejecuciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7669a1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents.agent import StopAtTools\n",
    "from agents import Agent, FunctionTool, RunContextWrapper, function_tool\n",
    "async def run_agents(mcp_servers, user_input):\n",
    "    \n",
    "    @function_tool\n",
    "    def human_in_the_loop(question: str):\n",
    "        '''\n",
    "        Esta tool te permite preguntar al usuario. No intentes preguntar al usuario sin usar esta tool\n",
    "        '''\n",
    "        return input(question)\n",
    "    \n",
    "    for server in mcp_servers:\n",
    "        await server.connect()\n",
    "    agent = Agent(name=\"Assistant\", \n",
    "                  instructions='''Eres un asistente financiero que puede hacer operaciones con el portafolio de un usuario, \n",
    "                  tienes una tool human_in_the_loop que te permite preguntar al usuario. No intentes preguntar al usuario sin usar esa tool ''', \n",
    "                  model=azure_model, \n",
    "                  mcp_servers=mcp_servers,\n",
    "                  tools=[human_in_the_loop],\n",
    "\n",
    "                  )\n",
    "    result = await Runner.run(agent, user_input)\n",
    "    return result.final_output\n",
    "\n",
    "async def create_mcps():\n",
    "    server_list = []\n",
    "    async with MCPServerStreamableHttp(\n",
    "        name=\"User Wallet\",\n",
    "        params={\n",
    "            \"url\": \"http://localhost:800/mcp/\"\n",
    "        }\n",
    "    ) as wallet_mcp:\n",
    "        wallet_mcp.connect()\n",
    "        server_list.append(wallet_mcp)\n",
    "        async with MCPServerStreamableHttp(\n",
    "            name=\"Financial live data\",\n",
    "            params={\n",
    "                \"url\": \"http://localhost:8002/mcp/\"\n",
    "            }\n",
    "        ) as financial_mcp:\n",
    "            financial_mcp.connect()\n",
    "            server_list.append(financial_mcp)\n",
    "            return server_list\n",
    "\n",
    "async def main():\n",
    "    question = input(\"En que puedo ayudarte?\")\n",
    "    server_list = await create_mcps()\n",
    "    res = await run_agents(server_list, question)\n",
    "\n",
    "await main() #Nota, fuera de jupyter, se debe usar asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc19ece",
   "metadata": {},
   "source": [
    "Vamos a añadir un segundo agente que haga busquedas web. Implementaremos una estrategia de handoff para que la ejecución pase a este segundo agente. \n",
    "OpenAI ya tiene busquedas web, pero para hacerlo agnostico respecto al modelo, utilizaremos Tavily, que es un proveedor externo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9420e64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tavily_api_key = \"tvly-dev- \"\n",
    "tavily_mcp_url = f\"https://mcp.tavily.com/mcp/?tavilyApiKey={tavily_api_key}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823f6b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents.agent import StopAtTools\n",
    "from agents import Agent, FunctionTool, RunContextWrapper, function_tool\n",
    "from agents.extensions.handoff_prompt import RECOMMENDED_PROMPT_PREFIX\n",
    "from agents.model_settings import ModelSettings\n",
    "\n",
    "\n",
    "user_wallet_mcp = MCPServerStreamableHttp(\n",
    "        name=\"User Wallet\",\n",
    "        params={\n",
    "            \"url\": \"http://localhost:800/mcp/\"\n",
    "        },\n",
    "        cache_tools_list=True\n",
    "    ) \n",
    "financial_mcp = MCPServerStreamableHttp(\n",
    "    name=\"Financial live data\",\n",
    "    params={\n",
    "        \"url\": \"http://localhost:8002/mcp/\"\n",
    "    },\n",
    "    cache_tools_list=True\n",
    ") \n",
    "web_search_mcp = MCPServerStreamableHttp(\n",
    "    name=\"Web search\",\n",
    "    params={\n",
    "        \"url\": \"https://mcp.tavily.com/mcp/?tavilyApiKey=tvly-dev- \"\n",
    "    },\n",
    "    client_session_timeout_seconds=10.0,\n",
    "    cache_tools_list=True\n",
    ")\n",
    "\n",
    "async def run_agents(user_input):\n",
    "    @function_tool\n",
    "    def human_in_the_loop(question: str):\n",
    "        '''\n",
    "        Esta tool te permite preguntar al usuario. No intentes preguntar al usuario sin usar esta tool\n",
    "        '''\n",
    "        return input(question)\n",
    " \n",
    "    async with user_wallet_mcp, financial_mcp, web_search_mcp:\n",
    "\n",
    "        wallet_agent = Agent(name=\"wallet_agent\", \n",
    "                    instructions='''Eres un asistente financiero que puede hacer operaciones con el portafolio de un usuario, \n",
    "                    tienes una tool human_in_the_loop que te permite preguntar al usuario o comunicar tus conclusiones. No intentes comunicarte con el usuario sin usar esa tool ''', \n",
    "                    model=azure_model, \n",
    "                    tools=[human_in_the_loop],\n",
    "                    mcp_servers=[user_wallet_mcp],\n",
    "\n",
    "\n",
    "                    )\n",
    "        research_agent = Agent(name=\"research_agent\", \n",
    "                            instructions='''Eres un agente de investigación financiera que puede \n",
    "                            hacer busquedas web mediante la tool web_search_mcp.\n",
    "                            Tienes una tool human_in_the_loop que te permite preguntar al usuario o coumunicar tus conclusiones. No intentes comunicarte con el usuario sin usar esa tool''',\n",
    "                            model=azure_model,\n",
    "                            mcp_servers=[web_search_mcp, financial_mcp],\n",
    "                            tools=[human_in_the_loop],\n",
    "                            )\n",
    "        assistant_agent = Agent(name=\"Assistant\", \n",
    "                    instructions=f'''{RECOMMENDED_PROMPT_PREFIX}\n",
    "                    Eres un asistente financiero que puede resolver varias tareas apoyandose en otros agentes especializados. \n",
    "                    tienes una tool human_in_the_loop que te permite preguntar al usuario. No intentes preguntar al usuario sin usar esa tool.\n",
    "                    Delega la conversación a un agente de investigación financiera si necesitas hacer una busqueda web o investigar datos de una accion en tiempo real.\n",
    "                    Delega la conversación a un agente de gestion de wallet si necesitas hacer operaciones con el portafolio de un usuario.\n",
    "                    Recuerda que tu conocimiento es limitado y no está actualizado, por lo que debes delegar las tareas a los agentes especializados.\n",
    "                    ''', \n",
    "                    model=azure_model, \n",
    "                    tools=[human_in_the_loop],\n",
    "                    handoffs=[research_agent, wallet_agent],\n",
    "                    )\n",
    "        \n",
    "\n",
    "        result = await Runner.run(assistant_agent, user_input, max_turns=30)\n",
    "        return result.final_output\n",
    "\n",
    "\n",
    "async def main():\n",
    "    # question = input(\"En que puedo ayudarte?\")\n",
    "    question = \"Invierte todo mi portfolio en algo que los analistas online consideren interesante. No me preguntes mucho.\"\n",
    "    res = await run_agents(question)\n",
    "\n",
    "await main() #Nota, fuera de jupyter, se debe usar asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb5fd97",
   "metadata": {},
   "source": [
    "Con este diseño conocido como \"Triaje\", un agente inicial decide a quien delegar la tarea, el problema es que cuando el agente investigador termina su parte, no puede llamar al agente que maneja la wallet para que ejecute la orden.\n",
    "\n",
    "Este diseño es un patrón interesante para tareas de soporte al cliente, en las que sea admisible que un cliente se vaya derivando a distintos especialistas IA y se comunique con ellos, pero no es tan interesante cuando queremos que se realice una tarea compleja de manera autónoma o semi autónoma.\n",
    "\n",
    "Por otro lado ¿Crees que el agente investigador tiene su responsabilidad bien acotada o crees que se extralimita?\n",
    "\n",
    "Para resolver esto podríamos:\n",
    "- Darle a todos los agentes la capacidad de hacer handoff en cualquiera de ellos.\n",
    "- Darle a todos los agentes la capacidad de usar la wallet\n",
    "- Obligar a los agentes a volver al asistente al terminar con el resultado.\n",
    "\n",
    "Implementemos esta última. En la librería que usamos la manera de hacerlo es usar \"agents-as-tools\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81bdf9c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9aa90ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents.agent import StopAtTools\n",
    "from agents import Agent, FunctionTool, RunContextWrapper, function_tool\n",
    "from agents.extensions.handoff_prompt import RECOMMENDED_PROMPT_PREFIX\n",
    "from agents.model_settings import ModelSettings\n",
    "\n",
    "\n",
    "user_wallet_mcp = MCPServerStreamableHttp(\n",
    "        name=\"User Wallet\",\n",
    "        params={\n",
    "            \"url\": \"http://localhost:800/mcp/\"\n",
    "        },\n",
    "        cache_tools_list=True\n",
    "    ) \n",
    "financial_mcp = MCPServerStreamableHttp(\n",
    "    name=\"Financial live data\",\n",
    "    params={\n",
    "        \"url\": \"http://localhost:8002/mcp/\"\n",
    "    },\n",
    "    cache_tools_list=True\n",
    ") \n",
    "web_search_mcp = MCPServerStreamableHttp(\n",
    "    name=\"Web search\",\n",
    "    params={\n",
    "        \"url\": \"https://mcp.tavily.com/mcp/?tavilyApiKey=tvly-dev- \"\n",
    "    },\n",
    "    client_session_timeout_seconds=10.0,\n",
    "    cache_tools_list=True\n",
    ")\n",
    "\n",
    "async def run_agents(user_input):\n",
    "    \n",
    "    @function_tool\n",
    "    def human_in_the_loop(question: str):\n",
    "        '''\n",
    "        Esta tool te permite preguntar al usuario. No intentes preguntar al usuario sin usar esta tool\n",
    "        '''\n",
    "        return input(question)\n",
    "    async with user_wallet_mcp, financial_mcp, web_search_mcp:\n",
    "\n",
    "    \n",
    "        wallet_agent = Agent(name=\"wallet_agent\", \n",
    "                    instructions='''Eres un asistente financiero que puede hacer operaciones con el portafolio de un usuario. \n",
    "                    Si se te pide algo que no puedes hacer, explica al usuario que no puedes hacerlo y si puedes sugiere \n",
    "                    algo similar que si puedes hacer. Todas tus capacidades son las que te ofrece el mcp de user_wallet_mcp''',\n",
    "                    model=azure_model,\n",
    "                    mcp_servers=[user_wallet_mcp],\n",
    "\n",
    "\n",
    "                    )\n",
    "        research_agent = Agent(name=\"research_agent\", \n",
    "                            instructions='''Eres un agente de investigación financiera que puede \n",
    "                            hacer busquedas web mediante la tool web_search_mcp. Tu objetivo es investigar, no hacer operaciones ni sacar conclusiones.\n",
    "                            Tienes un máximo de 10 intentos para investigar.\n",
    "                            Si ya los has usado, responde con lo que has investigado hasta el momento.\n",
    "                            ''',\n",
    "                            model=azure_model,\n",
    "                            mcp_servers=[web_search_mcp, financial_mcp],\n",
    "                            )\n",
    "        assistant_agent = Agent(name=\"Assistant\", \n",
    "                    instructions='''\n",
    "                    Eres un asistente financiero que puede resolver varias tareas apoyandose en otros agentes especializados. \n",
    "                    tienes una tool human_in_the_loop que te permite preguntar al usuario. No intentes preguntar al usuario sin usar esa tool.\n",
    "                    Delega la conversación a research_agent si necesitas hacer una busqueda web o investigar datos de una accion en tiempo real.\n",
    "                    Delega la conversación a wallet_agent si necesitas hacer operaciones con el portafolio de un usuario.\n",
    "                    Recuerda que tu conocimiento es limitado y no está actualizado, por lo que debes delegar las tareas a los agentes especializados.\n",
    "                    Tu coordinas a los agentes, extraes conclusiones y eres el único capaz de comunicarte con el usuario.\n",
    "                    ''', \n",
    "                    model=azure_model, \n",
    "                    tools=[human_in_the_loop, \n",
    "                        research_agent.as_tool(\n",
    "                            tool_name=\"research_agent\",\n",
    "                            tool_description=\"Busca información en la web o investiga datos de una accion en tiempo real\"\n",
    "                        ), \n",
    "                        wallet_agent.as_tool(\n",
    "                            tool_name=\"wallet_agent\",\n",
    "                            tool_description=\"Hace operaciones con el portafolio de un usuario\"\n",
    "                        )],\n",
    "                    )\n",
    "        \n",
    "\n",
    "        result = await Runner.run(assistant_agent, user_input, max_turns=30)\n",
    "        return result.final_output\n",
    "\n",
    "\n",
    "async def main():\n",
    "    # question = input(\"En que puedo ayudarte?\")\n",
    "    question = \"Invierte todo mi portfolio en algo que los analistas online consideren interesante. No me preguntes mucho.\"\n",
    "    res = await run_agents(question)\n",
    "\n",
    "await main() #Nota, fuera de jupyter, se debe usar asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84077a91",
   "metadata": {},
   "source": [
    "Tiene muy buena pinta, pero fijaos que los agentes agotan sus turnos con mucha facilidad (menos mal que los hemos limitado). Vamos a ver si podemos darle algunos turnos mas y poner algun fallback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b433d395",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents.agent import StopAtTools\n",
    "from agents import Agent, FunctionTool, RunContextWrapper, function_tool\n",
    "from agents.extensions.handoff_prompt import RECOMMENDED_PROMPT_PREFIX\n",
    "from agents.model_settings import ModelSettings\n",
    "from agents.exceptions import MaxTurnsExceeded, RunErrorDetails\n",
    "\n",
    "user_wallet_mcp = MCPServerStreamableHttp(\n",
    "        name=\"User Wallet\",\n",
    "        params={\n",
    "            \"url\": \"http://localhost:800/mcp/\"\n",
    "        },\n",
    "        cache_tools_list=True\n",
    "    ) \n",
    "financial_mcp = MCPServerStreamableHttp(\n",
    "    name=\"Financial live data\",\n",
    "    params={\n",
    "        \"url\": \"http://localhost:8002/mcp/\"\n",
    "    },\n",
    "    cache_tools_list=True\n",
    ") \n",
    "web_search_mcp = MCPServerStreamableHttp(\n",
    "    name=\"Web search\",\n",
    "    params={\n",
    "        \"url\": \"https://mcp.tavily.com/mcp/?tavilyApiKey=tvly-dev- \"\n",
    "    },\n",
    "    client_session_timeout_seconds=10.0,\n",
    "    cache_tools_list=True\n",
    ")\n",
    "\n",
    "async def run_agents(user_input):\n",
    "    @function_tool\n",
    "    def human_in_the_loop(question: str):\n",
    "        '''\n",
    "        Esta tool te permite preguntar al usuario. No intentes preguntar al usuario sin usar esta tool\n",
    "        '''\n",
    "        return input(question)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    async with user_wallet_mcp, financial_mcp, web_search_mcp:\n",
    "\n",
    "        @function_tool\n",
    "        async def research_agent(input: str) -> str:\n",
    "            \"\"\"Busca información en la web o investiga datos de una accion en tiempo real\"\"\"\n",
    "\n",
    "            research_agent = Agent(name=\"research_agent\", \n",
    "                instructions='''Eres un agente de investigación financiera que puede \n",
    "                hacer busquedas web mediante la tool web_search_mcp. Tu objetivo es investigar, no hacer operaciones ni sacar conclusiones.\n",
    "                ''',\n",
    "                model=azure_model,\n",
    "                mcp_servers=[web_search_mcp, financial_mcp],\n",
    "                )\n",
    "            try:\n",
    "                result = await Runner.run(\n",
    "                    research_agent,\n",
    "                    input=input,\n",
    "                    max_turns=15,\n",
    "                )\n",
    "                res = result.final_output\n",
    "            except MaxTurnsExceeded as e:\n",
    "                res = str(e.run_data)\n",
    "            return str(res)\n",
    "    \n",
    "        wallet_agent = Agent(name=\"wallet_agent\", \n",
    "                    instructions='''Eres un asistente financiero que puede hacer operaciones con el portafolio de un usuario. \n",
    "                    Si se te pide algo que no puedes hacer, explica al usuario que no puedes hacerlo y si puedes sugiere \n",
    "                    algo similar que si puedes hacer. Todas tus capacidades son las que te ofrece el mcp de user_wallet_mcp''',\n",
    "                    model=azure_model,\n",
    "                    mcp_servers=[user_wallet_mcp],\n",
    "\n",
    "\n",
    "                    )\n",
    "\n",
    "        assistant_agent = Agent(name=\"Assistant\", \n",
    "                    instructions='''\n",
    "                    Eres un asistente financiero que puede resolver varias tareas apoyandose en otros agentes especializados. \n",
    "                    tienes una tool human_in_the_loop que te permite preguntar al usuario. No intentes preguntar al usuario sin usar esa tool.\n",
    "                    Delega la conversación a research_agent si necesitas hacer una busqueda web o investigar datos de una accion en tiempo real.\n",
    "                    Delega la conversación a wallet_agent si necesitas hacer operaciones con el portafolio de un usuario.\n",
    "                    Recuerda que tu conocimiento es limitado y no está actualizado, por lo que debes delegar las tareas a los agentes especializados.\n",
    "                    Tu coordinas a los agentes, extraes conclusiones y eres el único capaz de comunicarte con el usuario.\n",
    "                    ''', \n",
    "                    model=azure_model, \n",
    "                    tools=[human_in_the_loop, research_agent,\n",
    "                        wallet_agent.as_tool(\n",
    "                            tool_name=\"wallet_agent\",\n",
    "                            tool_description=\"Hace operaciones con el portafolio de un usuario\"\n",
    "                        )],\n",
    "                    )\n",
    "        \n",
    "\n",
    "        result = await Runner.run(assistant_agent, user_input, max_turns=30)\n",
    "        return result.final_output\n",
    "\n",
    "\n",
    "async def main():\n",
    "    # question = input(\"En que puedo ayudarte?\")\n",
    "    question = \"Invierte todo mi portfolio en algo que los analistas online consideren interesante. No me preguntes mucho.\"\n",
    "    res = await run_agents(question)\n",
    "\n",
    "await main() #Nota, fuera de jupyter, se debe usar asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc77ece",
   "metadata": {},
   "source": [
    "En el sistema que estamos construyendo, la parte mas importante (y quizá la mas compleja) es la que hace la investigación. Vamos a tratar de hacer algo mas elaborado:\n",
    "- Transformar el investigador en un \"equipo\" de investigadores.\n",
    "- El que inicia la investigación es el \"jefe\" y va a comenzar con una planificación\n",
    "- A partir de la planificación, intentaremos paralelizar lo que sea posible.\n",
    "\n",
    "Por simplicidad, voy a dejar fuera la gestión de la wallet y voy a hacer el ejemplo acotado a esto, sería trivial añadir de nuevo el agente de la wallet si te apetece."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09555c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17:46:43.928 OpenAI Agents trace: Agent workflow\n",
      "17:46:43.936   Agent run: 'Assistant'\n",
      "17:46:43.937     Chat completion with 'gpt-5' [LLM]\n",
      "17:46:58.495     Function: human_in_the_loop\n",
      "17:49:53.145     Chat completion with 'gpt-5' [LLM]\n",
      "17:50:13.165     Function: human_in_the_loop\n",
      "17:50:52.863     Chat completion with 'gpt-5' [LLM]\n",
      "17:51:02.950     Function: research_agent\n",
      "17:51:02.954     Function: research_agent\n",
      "17:51:02.955     Function: research_agent\n",
      "17:51:02.955     Function: research_agent\n",
      "                 Function: research_agent\n",
      "17:51:02.961       MCP: list tools from server Web search\n",
      "                 Function: research_agent\n",
      "17:51:02.965       MCP: list tools from server Web search\n",
      "                 Function: research_agent\n",
      "17:51:02.966       MCP: list tools from server Web search\n",
      "                 Function: research_agent\n",
      "17:51:02.966       MCP: list tools from server Web search\n",
      "17:51:03.283       MCP: list tools from server Financial live data\n",
      "                 Function: research_agent\n",
      "17:51:03.337       MCP: list tools from server Financial live data\n",
      "                 Function: research_agent\n",
      "17:51:03.346       MCP: list tools from server Financial live data\n",
      "                 Function: research_agent\n",
      "17:51:03.368       MCP: list tools from server Financial live data\n",
      "                 Function: research_agent\n",
      "17:51:03.541       Agent run: 'research_agent'\n",
      "17:51:03.542         Chat completion with 'gpt-5-mini' [LLM]\n",
      "                 Function: research_agent\n",
      "17:51:03.701       Agent run: 'research_agent'\n",
      "                 Function: research_agent\n",
      "17:51:03.704       Agent run: 'research_agent'\n",
      "                 Function: research_agent\n",
      "17:51:03.705       Agent run: 'research_agent'\n",
      "                 Function: research_agent\n",
      "                   Agent run: 'research_agent'\n",
      "17:51:03.706         Chat completion with 'gpt-5-mini' [LLM]\n",
      "                 Function: research_agent\n",
      "                   Agent run: 'research_agent'\n",
      "17:51:03.708         Chat completion with 'gpt-5-mini' [LLM]\n",
      "                 Function: research_agent\n",
      "                   Agent run: 'research_agent'\n",
      "17:51:03.720         Chat completion with 'gpt-5-mini' [LLM]\n",
      "                 Function: research_agent\n",
      "                   Agent run: 'research_agent'\n",
      "17:51:06.447         Function: tavily_search\n",
      "                 Function: research_agent\n",
      "                   Agent run: 'research_agent'\n",
      "17:51:07.229         Function: tavily_search\n",
      "                 Function: research_agent\n",
      "                   Agent run: 'research_agent'\n",
      "17:51:07.827         Function: tavily_search\n",
      "                 Function: research_agent\n",
      "                   Agent run: 'research_agent'\n",
      "17:51:08.623         MCP: list tools from server Web search\n",
      "17:51:08.627         MCP: list tools from server Financial live data\n",
      "17:51:08.632         Chat completion with 'gpt-5-mini' [LLM]\n",
      "                 Function: research_agent\n",
      "                   Agent run: 'research_agent'\n",
      "17:51:08.866         MCP: list tools from server Web search\n",
      "17:51:08.867         MCP: list tools from server Financial live data\n",
      "17:51:08.870         Chat completion with 'gpt-5-mini' [LLM]\n",
      "                 Function: research_agent\n",
      "                   Agent run: 'research_agent'\n",
      "17:51:09.647         MCP: list tools from server Web search\n",
      "17:51:09.648         MCP: list tools from server Financial live data\n",
      "17:51:09.650         Chat completion with 'gpt-5-mini' [LLM]\n",
      "                 Function: research_agent\n",
      "                   Agent run: 'research_agent'\n",
      "17:51:10.833         Function: tavily_search\n",
      "                 Function: research_agent\n",
      "                   Agent run: 'research_agent'\n",
      "17:51:12.155         Function: tavily_search\n",
      "                 Function: research_agent\n",
      "                   Agent run: 'research_agent'\n",
      "17:51:12.835         MCP: list tools from server Web search\n",
      "17:51:12.835         MCP: list tools from server Financial live data\n",
      "17:51:12.846         Chat completion with 'gpt-5-mini' [LLM]\n",
      "                 Function: research_agent\n",
      "                   Agent run: 'research_agent'\n",
      "17:51:14.642         Function: tavily_search\n",
      "                 Function: research_agent\n",
      "                   Agent run: 'research_agent'\n",
      "17:51:14.886         Function: tavily_search\n",
      "17:51:14.888         Function: tavily_search\n",
      "17:51:14.892         Function: tavily_search\n",
      "17:51:14.896         Function: tavily_search\n",
      "17:51:14.899         Function: tavily_search\n",
      "17:51:14.899         Function: tavily_search\n",
      "17:51:14.899         Function: tavily_search\n",
      "17:51:14.900         Function: tavily_search\n",
      "                 Function: research_agent\n",
      "                   Agent run: 'research_agent'\n",
      "17:51:15.185         MCP: list tools from server Web search\n",
      "17:51:15.188         MCP: list tools from server Financial live data\n",
      "17:51:15.195         Chat completion with 'gpt-5-mini' [LLM]\n",
      "                 Function: research_agent\n",
      "                   Agent run: 'research_agent'\n",
      "17:51:16.991         MCP: list tools from server Web search\n",
      "17:51:16.991         MCP: list tools from server Financial live data\n",
      "17:51:16.995         Chat completion with 'gpt-5-mini' [LLM]\n",
      "                 Function: research_agent\n",
      "                   Agent run: 'research_agent'\n",
      "17:51:18.010         Function: tavily_search\n",
      "                 Function: research_agent\n",
      "                   Agent run: 'research_agent'\n",
      "17:51:19.287         Function: tavily_search\n",
      "                 Function: research_agent\n",
      "                   Agent run: 'research_agent'\n",
      "17:51:20.694         Function: tavily_search\n",
      "                 Function: research_agent\n",
      "                   Agent run: 'research_agent'\n",
      "17:51:22.177         MCP: list tools from server Web search\n",
      "17:51:22.181         MCP: list tools from server Financial live data\n",
      "17:51:22.190         Chat completion with 'gpt-5-mini' [LLM]\n",
      "                 Function: research_agent\n",
      "                   Agent run: 'research_agent'\n",
      "17:51:22.974         MCP: list tools from server Web search\n",
      "17:51:22.977         MCP: list tools from server Financial live data\n",
      "17:51:22.980         Chat completion with 'gpt-5-mini' [LLM]\n",
      "                 Function: research_agent\n",
      "                   Agent run: 'research_agent'\n",
      "17:51:23.986         MCP: list tools from server Web search\n",
      "17:51:23.993         MCP: list tools from server Financial live data\n",
      "17:51:23.994         Chat completion with 'gpt-5-mini' [LLM]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error invoking MCP tool tavily_search: Timed out while waiting for response to ClientRequest. Waited 10.0 seconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Function: research_agent\n",
      "                   Agent run: 'research_agent'\n",
      "17:51:25.126         Function: tavily_search\n",
      "17:51:27.292         MCP: list tools from server Web search\n",
      "17:51:27.292         MCP: list tools from server Financial live data\n",
      "17:51:27.297         Chat completion with 'gpt-5-mini' [LLM]\n",
      "                 Function: research_agent\n",
      "                   Agent run: 'research_agent'\n",
      "17:51:27.365         Function: tavily_extract\n",
      "17:51:28.112         MCP: list tools from server Web search\n",
      "17:51:28.115         MCP: list tools from server Financial live data\n",
      "17:51:28.118         Chat completion with 'gpt-5-mini' [LLM]\n",
      "                 Function: research_agent\n",
      "                   Agent run: 'research_agent'\n",
      "17:51:28.256         Function: tavily_search\n",
      "                 Function: research_agent\n",
      "                   Agent run: 'research_agent'\n",
      "17:51:29.640         Function: tavily_search\n",
      "                 Function: research_agent\n",
      "                   Agent run: 'research_agent'\n",
      "17:51:31.396         Function: tavily_search\n",
      "                 Function: research_agent\n",
      "                   Agent run: 'research_agent'\n",
      "17:51:31.930         MCP: list tools from server Web search\n",
      "17:51:31.930         MCP: list tools from server Financial live data\n",
      "17:51:31.930         Chat completion with 'gpt-5-mini' [LLM]\n",
      "17:51:34.669         Function: tavily_search\n",
      "                 Function: research_agent\n",
      "                   Agent run: 'research_agent'\n",
      "17:51:35.559         MCP: list tools from server Web search\n",
      "17:51:35.566         MCP: list tools from server Financial live data\n",
      "17:51:35.572         Chat completion with 'gpt-5-mini' [LLM]\n",
      "                 Function: research_agent\n",
      "                   Agent run: 'research_agent'\n",
      "17:51:36.241         MCP: list tools from server Web search\n",
      "17:51:36.247         MCP: list tools from server Financial live data\n",
      "17:51:36.254         Chat completion with 'gpt-5-mini' [LLM]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error invoking MCP tool tavily_search: Timed out while waiting for response to ClientRequest. Waited 10.0 seconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Function: research_agent\n",
      "                   Agent run: 'research_agent'\n",
      "17:51:39.427         Function: tavily_search\n",
      "                 Function: research_agent\n",
      "                   Agent run: 'research_agent'\n",
      "17:51:39.668         Function: tavily_search\n",
      "                 Function: research_agent\n",
      "                   Agent run: 'research_agent'\n",
      "17:51:41.310         MCP: list tools from server Web search\n",
      "17:51:41.316         MCP: list tools from server Financial live data\n",
      "17:51:41.326         Chat completion with 'gpt-5-mini' [LLM]\n",
      "                 Function: research_agent\n",
      "                   Agent run: 'research_agent'\n",
      "17:51:42.889         MCP: list tools from server Web search\n",
      "17:51:42.894         MCP: list tools from server Financial live data\n",
      "17:51:42.898         Chat completion with 'gpt-5-mini' [LLM]\n",
      "                 Function: research_agent\n",
      "                   Agent run: 'research_agent'\n",
      "17:51:44.677         Function: tavily_search\n",
      "                 Function: research_agent\n",
      "                   Agent run: 'research_agent'\n",
      "17:51:45.277         Function: tavily_search\n",
      "17:51:46.997         MCP: list tools from server Web search\n",
      "17:51:47.001         MCP: list tools from server Financial live data\n",
      "17:51:47.010         Chat completion with 'gpt-5-mini' [LLM]\n",
      "17:51:49.530         Function: tavily_extract\n",
      "17:51:50.606         MCP: list tools from server Web search\n",
      "17:51:50.613         MCP: list tools from server Financial live data\n",
      "17:51:50.618         Chat completion with 'gpt-5-mini' [LLM]\n",
      "                 Function: research_agent\n",
      "                   Agent run: 'research_agent'\n",
      "17:51:52.027         MCP: list tools from server Web search\n",
      "17:51:52.034         MCP: list tools from server Financial live data\n",
      "17:51:52.042         Chat completion with 'gpt-5-mini' [LLM]\n",
      "                 Function: research_agent\n",
      "                   Agent run: 'research_agent'\n",
      "17:51:53.468         Function: tavily_search\n",
      "17:51:54.786         MCP: list tools from server Web search\n",
      "17:51:54.796         MCP: list tools from server Financial live data\n",
      "17:51:54.804         Chat completion with 'gpt-5-mini' [LLM]\n",
      "                 Function: research_agent\n",
      "                   Agent run: 'research_agent'\n",
      "17:51:57.014         Function: tavily_search\n",
      "                 Function: research_agent\n",
      "                   Agent run: 'research_agent'\n",
      "17:52:02.568         Function: tavily_search\n",
      "17:52:03.989         MCP: list tools from server Web search\n",
      "17:52:03.998         MCP: list tools from server Financial live data\n",
      "17:52:04.003         Chat completion with 'gpt-5-mini' [LLM]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error invoking MCP tool tavily_search: Timed out while waiting for response to ClientRequest. Waited 10.0 seconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17:52:06.981         Function: tavily_search\n",
      "17:52:08.634         MCP: list tools from server Web search\n",
      "17:52:08.635         MCP: list tools from server Financial live data\n",
      "17:52:08.640         Chat completion with 'gpt-5-mini' [LLM]\n",
      "17:52:15.476         Function: tavily_search\n",
      "17:52:17.658         MCP: list tools from server Web search\n",
      "17:52:17.661         MCP: list tools from server Financial live data\n",
      "17:52:17.667         Chat completion with 'gpt-5-mini' [LLM]\n",
      "17:52:20.900         Function: tavily_search\n",
      "17:52:23.963         MCP: list tools from server Web search\n",
      "17:52:23.965         MCP: list tools from server Financial live data\n",
      "17:52:23.971         Chat completion with 'gpt-5-mini' [LLM]\n",
      "17:52:26.790         Function: tavily_search\n",
      "17:52:29.017         MCP: list tools from server Web search\n",
      "17:52:29.019         MCP: list tools from server Financial live data\n",
      "17:52:29.029     Chat completion with 'gpt-5' [LLM]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from agents import Agent, FunctionTool, RunContextWrapper, function_tool\n",
    "from agents.extensions.handoff_prompt import RECOMMENDED_PROMPT_PREFIX\n",
    "from agents.model_settings import ModelSettings\n",
    "from agents.exceptions import MaxTurnsExceeded, RunErrorDetails\n",
    "\n",
    "modelo_listo = agents.OpenAIChatCompletionsModel(openai_client=client, model=\"gpt-5\")\n",
    "\n",
    "financial_mcp = MCPServerStreamableHttp(\n",
    "    name=\"Financial live data\",\n",
    "    params={\n",
    "        \"url\": \"http://localhost:8002/mcp/\"\n",
    "    },\n",
    "    cache_tools_list=True\n",
    ") \n",
    "web_search_mcp = MCPServerStreamableHttp(\n",
    "    name=\"Web search\",\n",
    "    params={\n",
    "        \"url\": \"https://mcp.tavily.com/mcp/?tavilyApiKey=tvly-dev- \"\n",
    "    },\n",
    "    client_session_timeout_seconds=10.0,\n",
    "    cache_tools_list=True\n",
    ")\n",
    "\n",
    "async def run_agents(user_input):\n",
    "    @function_tool\n",
    "    def human_in_the_loop(question: str):\n",
    "        '''\n",
    "        Esta tool te permite preguntar al usuario. No intentes preguntar al usuario sin usar esta tool\n",
    "        '''\n",
    "        return input(question)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    async with  financial_mcp, web_search_mcp:\n",
    "\n",
    "        @function_tool\n",
    "        async def research_agent(input: str) -> str:\n",
    "            \"\"\"Agente que busca información en la web o investiga datos de una accion en tiempo real\"\"\"\n",
    "\n",
    "            research_agent = Agent(name=\"research_agent\", \n",
    "                instructions='''Eres un agente de investigación financiera que puede \n",
    "                hacer busquedas web mediante la tool web_search_mcp. Tu objetivo es investigar, no hacer operaciones ni sacar conclusiones.\n",
    "                Puedes probar diferentes palabras clave para encontrar la información que necesitas, pero no hagas demasiados experimentos.\n",
    "                Si crees que no puedes completar la tarea, responde con lo que has investigado hasta el momento y lo que has hecho para buscarlo \n",
    "                y el que te mandó la tarea sabrá como solucionarlo.\n",
    "                ''',\n",
    "                model=azure_model,\n",
    "\n",
    "                mcp_servers=[web_search_mcp, financial_mcp],\n",
    "                )\n",
    "            try:\n",
    "                result = await Runner.run(\n",
    "                    research_agent,\n",
    "                    input=input,\n",
    "                    max_turns=15,\n",
    "                )\n",
    "                res = result.final_output\n",
    "            except MaxTurnsExceeded as e:\n",
    "                res = str(e.run_data)\n",
    "            return str(res)\n",
    "    \n",
    "\n",
    "        assistant_agent = Agent(name=\"Assistant\", \n",
    "                    instructions='''\n",
    "                    Eres el jefe de un equipo de investigadores financieros. El cliente te va a plantear una consulta.\n",
    "                    Para resolverla, debes:\n",
    "                    - Escribir un plan de investigación, en el que partas la investigacion en varias investigaciones parciales.\n",
    "                    - Discrimina bien que partes son parelilzables y cuales son secuenciales.\n",
    "                    - Usando human_in_the_loop, confirma el plan con el cliente. También puedes usarla para pedirle \n",
    "                    que te ayude a escribir el plan. Pero ten en cuenta que el cliente tiene un conocimiento muy basico de finanzas\n",
    "                    - Cuando estés listo, delegas las partes en paralelo a los investigadores llamando a research_agent.\n",
    "                    - A medida que los investigadores van encontrando información, vas recopilando las conclusiones.\n",
    "                    - Puedes revisar el plan si algo no va bien, pero comunicaselo al cliente.\n",
    "\n",
    "                    ''', \n",
    "                    model=modelo_listo, \n",
    "                    model_settings=ModelSettings(reasoning={\"effort\": \"low\"}),\n",
    "                    tools=[human_in_the_loop, research_agent]\n",
    "                    )\n",
    "        \n",
    "\n",
    "        result = await Runner.run(assistant_agent, user_input, max_turns=30)\n",
    "        return result.final_output\n",
    "\n",
    "\n",
    "async def main():\n",
    "    # question = input(\"En que puedo ayudarte?\")\n",
    "    question = \"Tengo 1000€, dime si es mejor invertir en bitcoin, oro, materias primas o alguna empresa de defensa\"\n",
    "    res = await run_agents(question)\n",
    "\n",
    "await main() #Nota, fuera de jupyter, se debe usar asyncio.run(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6def8961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: openai-agents[viz] in c:\\users\\ginesrodrigo.sanchez\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (0.2.7)\n",
      "Requirement already satisfied: griffe<2,>=1.5.6 in c:\\users\\ginesrodrigo.sanchez\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from openai-agents[viz]) (1.12.1)\n",
      "Requirement already satisfied: mcp<2,>=1.11.0 in c:\\users\\ginesrodrigo.sanchez\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from openai-agents[viz]) (1.12.4)\n",
      "Requirement already satisfied: openai<2,>=1.99.6 in c:\\users\\ginesrodrigo.sanchez\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from openai-agents[viz]) (1.99.9)\n",
      "Requirement already satisfied: pydantic<3,>=2.10 in c:\\users\\ginesrodrigo.sanchez\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from openai-agents[viz]) (2.11.7)\n",
      "Requirement already satisfied: requests<3,>=2.0 in c:\\users\\ginesrodrigo.sanchez\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from openai-agents[viz]) (2.32.3)\n",
      "Requirement already satisfied: types-requests<3,>=2.0 in c:\\users\\ginesrodrigo.sanchez\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from openai-agents[viz]) (2.32.4.20250809)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.12.2 in c:\\users\\ginesrodrigo.sanchez\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from openai-agents[viz]) (4.14.1)\n",
      "Requirement already satisfied: graphviz>=0.17 in c:\\users\\ginesrodrigo.sanchez\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from openai-agents[viz]) (0.21)\n",
      "Requirement already satisfied: colorama>=0.4 in c:\\users\\ginesrodrigo.sanchez\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from griffe<2,>=1.5.6->openai-agents[viz]) (0.4.6)\n",
      "Requirement already satisfied: anyio>=4.5 in c:\\users\\ginesrodrigo.sanchez\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from mcp<2,>=1.11.0->openai-agents[viz]) (4.9.0)\n",
      "Requirement already satisfied: httpx-sse>=0.4 in c:\\users\\ginesrodrigo.sanchez\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from mcp<2,>=1.11.0->openai-agents[viz]) (0.4.1)\n",
      "Requirement already satisfied: httpx>=0.27 in c:\\users\\ginesrodrigo.sanchez\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from mcp<2,>=1.11.0->openai-agents[viz]) (0.28.1)\n",
      "Requirement already satisfied: jsonschema>=4.20.0 in c:\\users\\ginesrodrigo.sanchez\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from mcp<2,>=1.11.0->openai-agents[viz]) (4.25.0)\n",
      "Requirement already satisfied: pydantic-settings>=2.5.2 in c:\\users\\ginesrodrigo.sanchez\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from mcp<2,>=1.11.0->openai-agents[viz]) (2.9.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.9 in c:\\users\\ginesrodrigo.sanchez\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from mcp<2,>=1.11.0->openai-agents[viz]) (0.0.20)\n",
      "Requirement already satisfied: pywin32>=310 in c:\\users\\ginesrodrigo.sanchez\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from mcp<2,>=1.11.0->openai-agents[viz]) (311)\n",
      "Requirement already satisfied: sse-starlette>=1.6.1 in c:\\users\\ginesrodrigo.sanchez\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from mcp<2,>=1.11.0->openai-agents[viz]) (3.0.2)\n",
      "Requirement already satisfied: starlette>=0.27 in c:\\users\\ginesrodrigo.sanchez\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from mcp<2,>=1.11.0->openai-agents[viz]) (0.46.2)\n",
      "Requirement already satisfied: uvicorn>=0.23.1 in c:\\users\\ginesrodrigo.sanchez\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from mcp<2,>=1.11.0->openai-agents[viz]) (0.35.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\ginesrodrigo.sanchez\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from openai<2,>=1.99.6->openai-agents[viz]) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\ginesrodrigo.sanchez\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from openai<2,>=1.99.6->openai-agents[viz]) (0.10.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\ginesrodrigo.sanchez\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from openai<2,>=1.99.6->openai-agents[viz]) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\ginesrodrigo.sanchez\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from openai<2,>=1.99.6->openai-agents[viz]) (4.67.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\ginesrodrigo.sanchez\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pydantic<3,>=2.10->openai-agents[viz]) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\ginesrodrigo.sanchez\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pydantic<3,>=2.10->openai-agents[viz]) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\ginesrodrigo.sanchez\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pydantic<3,>=2.10->openai-agents[viz]) (0.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ginesrodrigo.sanchez\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests<3,>=2.0->openai-agents[viz]) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ginesrodrigo.sanchez\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests<3,>=2.0->openai-agents[viz]) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ginesrodrigo.sanchez\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests<3,>=2.0->openai-agents[viz]) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ginesrodrigo.sanchez\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests<3,>=2.0->openai-agents[viz]) (2025.7.14)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\ginesrodrigo.sanchez\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from httpx>=0.27->mcp<2,>=1.11.0->openai-agents[viz]) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\ginesrodrigo.sanchez\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from httpcore==1.*->httpx>=0.27->mcp<2,>=1.11.0->openai-agents[viz]) (0.16.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\ginesrodrigo.sanchez\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from jsonschema>=4.20.0->mcp<2,>=1.11.0->openai-agents[viz]) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\ginesrodrigo.sanchez\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from jsonschema>=4.20.0->mcp<2,>=1.11.0->openai-agents[viz]) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\ginesrodrigo.sanchez\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from jsonschema>=4.20.0->mcp<2,>=1.11.0->openai-agents[viz]) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\ginesrodrigo.sanchez\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from jsonschema>=4.20.0->mcp<2,>=1.11.0->openai-agents[viz]) (0.27.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\ginesrodrigo.sanchez\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pydantic-settings>=2.5.2->mcp<2,>=1.11.0->openai-agents[viz]) (1.1.1)\n",
      "Requirement already satisfied: click>=7.0 in c:\\users\\ginesrodrigo.sanchez\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from uvicorn>=0.23.1->mcp<2,>=1.11.0->openai-agents[viz]) (8.2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.2\n",
      "[notice] To update, run: C:\\Users\\ginesrodrigo.sanchez\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install \"openai-agents[viz]\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
